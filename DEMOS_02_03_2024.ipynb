{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NZmJwHg3k8At",
        "eq6PQO2ChASy",
        "Uf41g9HSf_uV",
        "KcLnfoMhdv98",
        "89RrGfjIbUCp"
      ],
      "authorship_tag": "ABX9TyMthqpXdmHrit7xZFuIgxWG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlatundeEso/AI-Chatbot/blob/master/DEMOS_02_03_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "we5S6Tl3ekiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYkCJQsaf-hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESUME CUSTOMIZER APP\n",
        "## The Solution is a Copy of Nothing!\n",
        "### The Architecture, Logic, Reasoning and build of this Application/platform does not borrow from any existing project on the internet or other repositories.\n"
      ],
      "metadata": {
        "id": "NZmJwHg3k8At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai\n",
        "!pip install streamlit\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain import PromptTemplate\n",
        "my_openai_key = \"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\"\n",
        "import os\n",
        "os.environ['OPEN_AI_KEY'] = \"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\"\n",
        "os.environ['OPEN_AI_KEY'] = my_openai_key\n",
        "llm = ChatOpenAI(openai_api_key = my_openai_key, temperature = 0)"
      ],
      "metadata": {
        "id": "087bmHOcf-TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# app config\n",
        "#%%writefile functionalresumeapp.py\n",
        "\n",
        "import _thread  # Import the _thread module\n",
        "import ssl\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain import PromptTemplate\n",
        "my_openai_key = \"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\"\n",
        "import os\n",
        "import streamlit as st\n",
        "os.environ['OPEN_AI_KEY'] = \"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\"\n",
        "os.environ['OPEN_AI_KEY'] = my_openai_key\n",
        "\n",
        "st.set_page_config(page_title=\"Resume Customization Assistant\", page_icon=\"ðŸ¤–\")\n",
        "st.title(\"Customize Your Resume\")\n",
        "llm = ChatOpenAI(openai_api_key = my_openai_key, temperature = 0) #Commenting it out so that the model is not loaded everytime\n",
        "\n",
        "\n",
        "\n",
        "# THE APPLICATION FUNCTION DEFINITIONS HERE\n",
        "\n",
        "#st.cache_data\n",
        "def get_user_input():\n",
        "  old_resume = st.text_input(\"Please copy and paste your old CV here\")\n",
        "  job_opening = st.text_input(\"Please copy and paste the Job Description of the job being applied for here\")\n",
        "\n",
        "  return old_resume, job_opening\n",
        "\n",
        "@st.cache_data\n",
        "def retrieve_job_extract_and_resume_portion_update_resume_auto(job_opening, dorgsndates, old_resume):\n",
        "    template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an advertised job. Do not (NEVER) make anything up by yourself, STRICTLY FOCUS ON THE DOCUMENTS SHARED WITH YOU TO PROVIDE RESPONSES. If you don't have an answer, make it clear that you don't know. Think step by step, your task is to extract and list each and every (ALL) important job description and skill requirements in this job description\\n{job_description}\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm=llm, prompt=prompt_1, output_key='job_description_extract')\n",
        "\n",
        "\n",
        "    template_2 = \"You are an expert and professional employee actively practicing in your field. Do not (NEVER) make anything up. You MUST provide relevant, valid, creative and effective response even if the document is simply a list of tasks for a given job role. STRICTLY FOCUS ON THE DOCUMENTS SHARED WITH YOU TO PROVIDE RESPONSES. If you dont have an answer, or if the document doesn't seem to be related to a job task/activity, make it clear that you are unable to help and ask the user to supply a list of job tasks. Your task is to develop a list of Job responsibilities from the document below which can be inserted into a Resume as if you are applying for a job. You are to develop/generate a well-detailed, compliant, and matching list of responsibilities so that they describe your previous experiences, knowledge, skills, experiences, and competences matching the details in the document below\\n{job_description_extract}\"\n",
        "    prompt_2 = ChatPromptTemplate.from_template(template_2)\n",
        "    chain_2 = LLMChain(llm=llm, prompt=prompt_2, output_key='resume_portion')\n",
        "\n",
        "    # Now template 4 to Generate the Previous Roles with Dates\n",
        "    template_4 = \"You are a very meticulous and very detailed individual who is an expert in generating/curating a list which narrates your previous responsibilities (ONLY the responsibilities) in the organizations you have previously worked for. You task is to spread these previous responsibilities below, delimited within the asterics(** **), among these recognized organizations (with the respective dates you worked there) {org_and_date}\\n. Ensure you insert each and every responsibility (that were captured) into the list below, but spread them in no particular order among the recognized organizations.  Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. If the document you receive does not have job responsibilities/roles, tell the user that you are unable to assist. LET THE TENSES YOU USE BE PAST TENSES (e.g 'Supported the team that delivered the Cloud Migration project using AWS services for Access Bank, Lagos') The responsibilities are here below:\\n**{resume_portion}** \"\n",
        "    # If the supplied document does not look like a Resume or CV, tell the user to upload a valid Resume/CV, without which you are unable to assist.\n",
        "    prompt_4 = ChatPromptTemplate.from_template(template_4)\n",
        "    chain_4 = LLMChain(llm = llm, prompt=prompt_4, output_key='previous_roles_with_dates')\n",
        "\n",
        "    # template 5 that Generates an Updated Resume Automatically - Not Recommended as we want the User to remain in Control the narrative that goes into their Resume. LLM today are still grossly INDETERMINATE\n",
        "    # and can generate non-representative description about you. Your profile is in your hands\n",
        "\n",
        "    template_5 = \"You are great at updating and customizing your old resume to fit a new job you are applying for. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. You put all your strong points forward. You are very known as very spot-on and competent in interlacing, interweaving and integrating your previous and present job roles/responsibilities into your old resume so that you can create an updated Resume to make it very compliant to the demands of a new job you are applying for. You have achieved great successes in doing this in the past. You are to ADD, integrate, digest, interlace, interweave ALL these previous roles below \\n {previous_roles_with_dates}\\n into the old resume below delimited in square brackets below so that a single, whole and robust (heterogenous mix of both contents/documents) is generated as a result. \\nUse same formatting style, font type/size, bullet types, and formatting layout present in the old resume. In the resulting updated Resume, ensure that the responsibilities in the MOST RECENT COMPANY/ORGANIZATION are WRITTEN IN PRESENT CONTINUOUS TENSES. ALL other Job responsibilites in other WORKPLACES/ORGANIZATIONS are written in PAST TENSES. NEVER repeat any responsibility or sentence in the updated resume. The old resume is here below:\\n [{old_cv}]\" # WITHOUT LOSING ANY DETAILS IN THE JOB ROLE AND RESPONSIBILITIES PRESENT IN THE OLD RESUME,\n",
        "    prompt_5 = ChatPromptTemplate.from_template(template_5)\n",
        "    chain_5 = LLMChain(llm = llm, prompt=prompt_5, output_key='updated_resume')\n",
        "\n",
        "    # Now, trying to generate the results of developing the updated resume\n",
        "\n",
        "    updated_resume_chain = SequentialChain(\n",
        "        chains = [chain_1, chain_2,  chain_4, chain_5],\n",
        "        input_variables = ['job_description', 'org_and_date', 'old_cv'],\n",
        "        output_variables = ['job_description_extract', 'resume_portion', 'previous_roles_with_dates', 'updated_resume'],\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    updated_resume_results = updated_resume_chain({\"job_description\": job_opening, 'org_and_date' : dorgsndates, \"old_cv\": old_resume, })\n",
        "\n",
        "    important_jd = updated_resume_results[\"job_description_extract\"]\n",
        "    previous_jobroles = updated_resume_results[\"resume_portion\"]\n",
        "    previous_roles_n_dates = updated_resume_results[\"previous_roles_with_dates\"]\n",
        "    auto_updated_resume = updated_resume_results[\"updated_resume\"]\n",
        "\n",
        "    return important_jd, previous_jobroles, previous_roles_n_dates, auto_updated_resume\n",
        "\n",
        "\n",
        "@st.cache_data\n",
        "def retrieve_previous_organizations_and_dates(old_resume):\n",
        "  # Now template 3 goes in\n",
        "    dorgsndates = \"\"  #  Initiating this to an empty string as it kept halucinating\n",
        "    template_3 = \"\"\"You are an expert and professional employee actively practicing in your field and have worked with a few organizations. You are proud of these organizations and the periods you worked with each of these organizations. Do not (NEVER) make anything up, do not list any arbitrary company/organization except the user supplies such for you. If you dont have an answer, make it clear that you dont know. Your task is to recognize and list/write out these individual organizations you have worked with previously (entity recognition) including the dates you worked with them based on your old resume detailed here\\n {old_cv}. Return only the details required and no other phrase or sentence. Example of a response is \"1. Jaguar Land Rover, Gaydon UK\n",
        "    - Position: AI Consultant Cum Scrum Master\n",
        "        - Dates: Nov 2022 - Present \"\n",
        "    \"\"\"\n",
        "    prompt_3 = ChatPromptTemplate.from_template(template_3)\n",
        "    chain_3 = LLMChain(llm = llm, prompt=prompt_3)   # removed output_key='organization_and_dates')\n",
        "\n",
        "    # Now the Organizations the Candidate has previously worked for and dates goes here:\n",
        "\n",
        "    dorgsndates = chain_3.run(old_resume)  # dorgsndates is short for \"d_organizations_and_dates ()\" We run this chain to retrieve the organizations worked with and the dates.\n",
        "    # dorgsndates\n",
        "\n",
        "    st.write(\"This is where I will explain that the application will list the previous place you have worked\")\n",
        "    st.write(\"\")\n",
        "    st.write(\"\")\n",
        "    # This will check the previous companies that the candidate had worked with previously\n",
        "    #\n",
        "    return dorgsndates\n",
        "\n",
        "@st.cache_data\n",
        "def check_resume_match_with_jd(job_opening, old_resume):\n",
        "\n",
        "    template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an an advertized job. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description\\n{job_description}\"\n",
        "    # template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an an advertized job. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description below (adding other relevant key requirements, expertise, skills and  experiences that may be required for the role/job description) \\n{job_description}\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm = llm, prompt=prompt_1, output_key='job_description_extract')\n",
        "\n",
        "\n",
        "    template_6 = \"You are an expert in reviewing candidates' resume against job description to shortlist only qualified candidates whose Resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Your expertise is top-notch in the careful perusal of the received Resume comparing it with the job description received from the hiring organization with the intention to determine the candidate's fit/qualification for the job. Let us think step-by-step. Be logical and do not rush to an answer but do review and analyze the entire documents shared with you properly. Your task is to come up with a similarity score (on a scale of 0-100%) after comparing this job description {job_description_extract} with the candidate CV here below\\n{old_cv}\"\n",
        "    prompt_6 = ChatPromptTemplate.from_template(template_6)\n",
        "    chain_6 = LLMChain(llm = llm, prompt=prompt_6, output_key='initial_similarity_score')\n",
        "\n",
        "    cv_review_chain = SequentialChain(\n",
        "        chains = [chain_1, chain_6],\n",
        "        input_variables = ['job_description', 'old_cv'],\n",
        "        output_variables = ['initial_similarity_score'],\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    cv_review_results = cv_review_chain({\"job_description\" : job_opening, \"old_cv\": old_resume})\n",
        "    return cv_review_results['initial_similarity_score']\n",
        "\n",
        "@st.cache_data\n",
        "def check_resume_match_with_jd_tabular(job_opening, old_resume):\n",
        "   # Generating Resume match in Tabular Form\n",
        "\n",
        "    template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an an advertized job. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description\\n{job_description}\"\n",
        "    # template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an an advertized job. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description below (adding other relevant key requirements, expertise, skills and  experiences that may be required for the role/job description) \\n{job_description}\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm = llm, prompt=prompt_1, output_key='job_description_extract')\n",
        "\n",
        "\n",
        "    template_6a = \"You are an expert in reviewing candidates' resume against job description to shortlist only qualified candidates whose Resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Your expertise is top-notch in the careful perusal of the received Resume comparing it with the job description received from the hiring organization with the intention to determine the candidate's fit/qualification for the job. Be logical and do not rush to an answer but do review and analyze the entire documents shared with you properly. Your task is to come up with a similarity score (expressing it as an OVERALL SUMMARY/FINAL similarity score )on a scale of 0-100% ONLY IN TABULATED FORMAT. Come up with a well-formatted HTML table for the final average % after determining the individual percentages for each assessement area after comparing this job description {job_description_extract} with the candidate CV here below\\n{old_cv}\"\n",
        "    prompt_6a = ChatPromptTemplate.from_template(template_6a)\n",
        "    chain_6a = LLMChain(llm = llm, prompt=prompt_6a, output_key='initial_similarity_score_tabulated')\n",
        "\n",
        "    cv_review_chain_a = SequentialChain(\n",
        "        chains = [chain_1, chain_6a],\n",
        "        input_variables = ['job_description', 'old_cv'],\n",
        "        output_variables = ['initial_similarity_score_tabulated'],\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    cv_review_results_tabulated = cv_review_chain_a({\"job_description\" : job_opening, \"old_cv\": old_resume})\n",
        "    return cv_review_results_tabulated['initial_similarity_score_tabulated']\n",
        "\n",
        "@st.cache_data\n",
        "def determine_display_skill_gap(job_opening, old_resume):\n",
        "    # Now Giving Feedback on Skill Gaps Based on the Relevance/Match of the Job Description and Candidate's Resume\n",
        "\n",
        "    template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an advertised job. Do not (NEVER) make anything up. If you don't have an answer, make it clear that you don't know. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description\\n{job_description}\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm=llm, prompt=prompt_1, output_key='job_description_extract')\n",
        "\n",
        "\n",
        "    template_7 = \"You are an expert in reviewing candidate's resume against job description to shortlist only qualified candidates whose resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. THERE IS NO NEED for the candidate to list specific examples for each area of competence, experience or skills (a simple mentioning of the requirements listed in the job description is sufficient to qualify them for shortlisting). DO NOT make any issue against a candidate who didnt provide specific examples of skills, competencies or experiences. Only discuss gaps that were not mentioned at all. Your task is to come up with a detailed list of the gaps in the candidate's skills, experiences and competencies after comparing this job description {job_description_extract} with the candidate CV here below\\n{old_cv}\"\n",
        "    prompt_7 = ChatPromptTemplate.from_template(template_7)\n",
        "    chain_7 = LLMChain(llm = llm, prompt=prompt_7, output_key='skill_gaps')\n",
        "\n",
        "    skill_gaps_chain = SequentialChain(\n",
        "        chains = [chain_1, chain_7],\n",
        "        input_variables = ['job_description', 'old_cv'],\n",
        "        output_variables = ['job_description_extract', 'skill_gaps'],\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    skill_gaps_results = skill_gaps_chain({\"job_description\" : job_opening, \"old_cv\": old_resume})\n",
        "\n",
        "    identified_skill_gaps = skill_gaps_results['skill_gaps']\n",
        "    return identified_skill_gaps\n",
        "\n",
        "\n",
        "@st.cache_data\n",
        "def give_suggestion(job_opening, identified_skill_gaps):\n",
        "  # Now, Let us Give Suggestions to the Candidate\n",
        "\n",
        "    template_8 = \"You are an expert job-haunting coach who is great and has achieved repeated successes in coaching and preparing candidates for job interviews, based on their skill gaps. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. You usually provide both short term and long term suggestions for the candidates to ace at job interviews. The short term suggestions and advice are what the candidate can do to brush up for the coming interviews. Given that they are applying for the job role with the job description here\\n{job_description}, you are to GENERATE A LIST of SHORT TERM and LONG TERM suggestions for this candidate after you have completed a thorough perusal of their identified skill gaps here below\\n{skill_gaps}\"\n",
        "    prompt_8 = ChatPromptTemplate.from_template(template_8)\n",
        "    chain_8 = LLMChain(llm = llm, prompt=prompt_8, output_key='suggestions')\n",
        "\n",
        "    suggestion_for_candidate = chain_8.run({'job_description': job_opening, 'skill_gaps': identified_skill_gaps})\n",
        "    return suggestion_for_candidate\n",
        "\n",
        "##### THIS IS THE LAST TWO FUNCTIONS TO USE #######\n",
        "\n",
        "#@st.cache_data  # Trying to make sure this re-runs so that when users updates the CV, this is updated.\n",
        "def give_candidate_score_after_manual_update(job_opening, candidate_updated_resume_manual):\n",
        "    #template_9 = \"You are an expert in reviewing candidates' Resumes against a job description to shortlist only qualified candidates whose Resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Your expertise is top-notch in the careful perusal of the received Resume and comparing it with the job description received from the hiring organization. Your task is to determine the candidate's fit/qualification for the job. You are to come up with a similarity score (on a scale of 0-100%) after comparing this job description {job_description} with the candidate's Resume here below\\n{updated_resume}\"\n",
        "    template_9 = \"You are an expert in carefully reviewing/perusing a candidate's Resumes against a job description. Your task is to det\n",
        "    # You are an expert at generating a score of how well a resume matches a given job description, capturing the relevant keywords and the important job requirements detailed in the Job Description. You ALWAYS provide a score of how well the resume captures and matches the important job needs, skill requirements, experience and specific technologies that are documented in the Job Description. Confirm if alll the important details of this job description {job description} are covered in this Job resume {\"Manually Updated Resume\"}\n",
        "    prompt_9 = ChatPromptTemplate.from_template(template_9)ermine what percentage of the details/requirements the Job Description is reflected/addressed/captured in the Resume. You are to come up with a score on a scale of 0% to 100% based on this assessment. If all of the Job Description is included in the Resume, then the score is 100%, if none of the Job Description is contained in the Resume, then score is 0% - others are in-between. Think Step by Step and logically. DO NOT make anything up, ONLY USE THE DOCUMENTS PROVIDED TO YOU...do not use generic documents. YOU MUST CAREFULLY Read through the document from the beginning to the end ensuring you match context for context, any error in % mapping will be severely dealt with, so you must be thorough in your assessment and evaluation.. If the document you are comparing the Job Description with doesn't look a Resume, let the User understand this and let them know you cannot proceed until a valid Resume is supplied. This is the Job Description \\n {job_description} and the Resume is here below\\n\\n{updated_resume}\"\n",
        "    chain_9 = LLMChain(llm = llm, prompt=prompt_9, output_key='final_similarity_score_manual')\n",
        "\n",
        "    final_candidate_score_manual= chain_9.run({'job_description': job_opening, 'updated_resume': candidate_updated_resume_manual})\n",
        "    return final_candidate_score_manual\n",
        "\n",
        "@st.cache_data\n",
        "def give_candidate_score_after_manual_update_tabular(job_opening, candidate_updated_resume_manual):\n",
        "    template_9a = \"You are an expert in reviewing a candidate's Resumes against a job description. DO NOT make anything up, ONLY USE THE DOCUMENTS PROVIDED TO YOU...do not use generic documents and compare context for context. If you dont have an answer, make it clear that you dont know. Your task is to determine what percentage of the Job Description is reflected in the Resume - You are to come up with a percentage score on a scale of 0% to 100%. If all of the Job Description is included in the Resume, then the score is 100%, if none of the Job Description is contained in the Resume, then score is 0% - others are in-between. YOU SHOULD RETURN YOUR FINDINGS IN TABULAR FORM. This is the Job Description \\n {job_description} and the Resume is here below\\n\\n{updated_resume}\"\n",
        "    #template_9a = \"You are an expert in reviewing candidates' Resumes against a job description to shortlist only qualified candidates whose Resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Your expertise is top-notch in the careful perusal of the received Resume and comparing it with the job description received from the hiring organization. Your task is to determine the candidate's fit/qualification for the job. You are to come up with a similarity score (on a scale of 0-100%) RETURNED IN TABULAR FORM after comparing this job description {job_description} with the candidate's Resume here below\\n{updated_resume}\"\n",
        "    prompt_9a = ChatPromptTemplate.from_template(template_9a)\n",
        "    chain_9a = LLMChain(llm = llm, prompt=prompt_9a, output_key='final_similarity_score_manual_tabular')\n",
        "\n",
        "    final_candidate_score_manual_tabular = chain_9a.run({'job_description': job_opening, 'updated_resume': candidate_updated_resume_manual}) # Consider Changing the documents- job_opening to important_jd or previous_jobroles\n",
        "    return final_candidate_score_manual_tabular\n",
        "\n",
        "@st.cache_data\n",
        "def generate_cover_letter(job_opening, candidate_updated_resume_manual):\n",
        "  template_10 = \"\"\" You are a professional consultant known for generating very captivating and effective Cover Letters when supplied with a Job Description.\n",
        "  You creatively use the combination of the received Job Description and your Resume to generate a top-notch Cover Letter that is irresistible, well matched to the Job Description and aligned with your Resume.\n",
        "  Given the Job Description/Requirements delimited below by double angle brackets, and your Resume delimited by triple asterisk delimiters in the lines below, your task is to generate a Cover Letter.\n",
        "  The Cover Letter should portray you as best suited for the position in the JOb Description, showing your interest in the job, and presenting your skills, certifications, education and experiences (based on your Resume and Job Description) effectively in short but impactful/catchy paragraphs.\n",
        "  The Cover Letter must portray you as being self-motivated, a good leader and a well-organized individual. It must also reflect you as meeting/surpassing the requirements in the Job Description\n",
        "  <<{job_descrip}>>\n",
        "  ***{your_resume}***\n",
        "  \"\"\"\n",
        "  # Thinking of including this line, see if it helps the Cover Letter better - The cover-letter creation must be both creative and pragmatic so that readers are never able to tell that an AI wrote this.\n",
        "  prompt_10 = ChatPromptTemplate.from_template(template_10)\n",
        "  chain_10 = LLMChain(llm = llm, prompt=prompt_10, output_key='cover_letter')\n",
        "\n",
        "  cover_letter = chain_10.run({'job_descrip': job_opening, 'your_resume': candidate_updated_resume_manual}) #\n",
        "  return cover_letter\n",
        "\n",
        "## THE MAIN PROGRAM CALLS HERE\n",
        "\n",
        "# NOW GOING INTO THE CODE PROPER\n",
        "\n",
        "def main():\n",
        "\n",
        "  with st.sidebar:\n",
        "    st.header(\"Your Documents Here\")\n",
        "    st.markdown(\"## Usage of the App\")\n",
        "    st.write(\"**How to Use**\")\n",
        "    st.write(\"These are the simple ways of using the App.........\")\n",
        "    st.write(\" \")\n",
        "    st.divider()\n",
        "    old_resume, job_opening = get_user_input()\n",
        "    st.markdown(\"Perhaps Goes In an Expander - Click to Read More\")\n",
        "    # with st.expander(\"Intent of the Application....Click to Read More\"):\n",
        "    #   st.write(\"\"\"\n",
        "    #             Note that the intent of this Resume Assistant is not to aid you in telling lies about your abilities, competence, skills and/or experiences, rather it helps you articulate and emphasize your professional skills, tailoring your resume to the requirements of the job, (which we assume you meet but unable to succinctly put together at the same speed of this application) and making sure that the hiring/hr managers select your Resume as qualified for the advertised role. Tailoring your resume takes time and effort but itâ€™s definitely worth it â€“ this is the whole essence of this Assistant!\n",
        "    #   \"\"\")\n",
        "    # with st.expander(\"Click Here to Read More\"):\n",
        "    #   st.write(\"\"\"\n",
        "    #   Ensure that the suggestions given to you are properly worded to your taste and inserted as close as possible to the top of the Resume. This could mean trying to have these suggestions included in your most recent job role.\n",
        "    #   You are responsible for not telling a lie about your capabilities and abilities. Ensure that the position/location you insert a particular suggested job responsibilities aligns and fits well with the Job role/Organization\n",
        "    #   Use the right tense. It is suggested to use present continous tense for your present role and active past tense for your past roles and responsibilities.\n",
        "    #   Infuse the generated job responsibilities intuitively into your Resume such that there is a homogenous mix of the two. Interlace and interweave them into your existing Resume.\n",
        "    #   Make sure you include other required expert knowledge, certifications, experiences, skills and required competencies the Resume.\n",
        "    #   Use the relevant job titles, the name of the companies and dates of employments in your Resume. Clear headlines depicting these makes your Resume to be more ATS friendly.\n",
        "    #   The responsibility of review of the suggested responsibilities lies with you. You should ensure that the generated suggestions are infused, spread and distributed within your present Resume in a coherent manner while maintain a professional, reasonable and logical flow so as to reflect that you own the experiences, competencies, and skills in the resultant Customized Resume .\n",
        "    #   \"\"\")\n",
        "    # st.write(\"\"\" Top Tips\n",
        "    # Use the top half of your resumeâ€™s first page.\n",
        "    # Together with your contact information and Resume Summary, your job description is one of the first things recruiters and hiring managers read in your resume.\n",
        "    # Since recruiters only spend around seven seconds before they either rule you out or move you to the next round, it is imperative that you put your most attractive job roles and responsibilities (that maps well to the advertised job description) in the top half section of your resume.\n",
        "\n",
        "    # \"\"\")\n",
        "    # Include a brief attention grabbing and relevant headline that is aligned with the job title, right after your name.. Should be on the top part of the resume, just after the contact details\n",
        "    # Find the relevant skills in the Job Descriptionand add them to the Skills section. If there is no such section in the resume presently, create it and add the needed skills\n",
        "\n",
        "  if old_resume is None or old_resume == \"\":\n",
        "      st.info(\"Please paste your present Resume into the side-bar <---\")\n",
        "\n",
        "  if job_opening is None or job_opening == \"\":\n",
        "      st.info(\"Please paste the Job Description into the side-bar <---\")\n",
        "\n",
        "  if old_resume and job_opening:\n",
        "      # NOW UNTO THE PREVIOUS ORGANIZATIONS AND DATES\n",
        "      dorgsndates = retrieve_previous_organizations_and_dates(old_resume)\n",
        "      if st.button(\"Show Previous Companies\", key = \"show_prev\"):\n",
        "        st.write(f\"The organization the candidates has worked with before is\\n {dorgsndates}\")\n",
        "\n",
        "\n",
        "      # For Chain 1, 2 4 and 5\n",
        "\n",
        "      important_jd, previous_jobroles, previous_roles_n_dates, auto_updated_resume = retrieve_job_extract_and_resume_portion_update_resume_auto(job_opening, dorgsndates, old_resume)\n",
        "\n",
        "      # st.write(\"This is where I will explain the process of automatically updating the resume\")\n",
        "      # st.write(\"\")\n",
        "      # st.write(\"\")\n",
        "\n",
        "      # #if updated_resume_results is not None and updated_resume_results != \"\":  # This is the original write-up\n",
        "      # if updated_resume_results and st.button(\"Show Previous Companies\"):  # Checking if this will help with keeping the one below it quiet\n",
        "      #   if st.button(\"Show Updated Resume\", key = \"updated resume\"):\n",
        "      #     st.write(f\"The updated Resume is\\n {candidate_updated_resume}\")\n",
        "\n",
        "    # USING FORMS FOR THESE FOUR OUTPUTS\n",
        "\n",
        "      if previous_jobroles not in st.session_state:        # ADDED THIS TO KEEP previous_jobroles PERSISTENT\n",
        "        st.session_state.previous_jobroles = previous_jobroles  # SAME HERE\n",
        "\n",
        "      with st.form(\"What to Retrieve\"):\n",
        "        doc_to_retrieve = st.selectbox(\"Document to Retrieve\", [\"The Job Description Extract\", \"Previous Job Roles\", \"Previous Job Roles with Dates\", \"Automated Generated Resume\"], index=1)\n",
        "        submit_button = st.form_submit_button(\"Retrieve\")\n",
        "\n",
        "        if submit_button and (doc_to_retrieve == \"The Job Description Extract\"):\n",
        "          st.write(important_jd)\n",
        "\n",
        "        elif submit_button and (doc_to_retrieve == \"Previous Job Roles\"):\n",
        "          st.write(st.session_state.previous_jobroles) # THIS IS NOW UPGRADED ALSO\n",
        "\n",
        "        elif submit_button and (doc_to_retrieve == \"Previous Job Roles with Dates\"):\n",
        "          st.write(previous_roles_n_dates)\n",
        "\n",
        "        elif submit_button and (doc_to_retrieve == \"Automated Generated Resume\"):\n",
        "          st.write(auto_updated_resume)\n",
        "\n",
        "\n",
        "      # NOW LET US GET THE RESULT OF THE CV REVIEW\n",
        "\n",
        "      cv_review_results_initial_similarity_score = check_resume_match_with_jd(job_opening, old_resume)\n",
        "\n",
        "      st.write(\"This is where I will explain what happens here\")\n",
        "      st.write(\"\")\n",
        "      st.write(\"\")\n",
        "\n",
        "      if cv_review_results_initial_similarity_score:\n",
        "        if st.button(\"Show Resume Match\", key = \"resume_match\"):\n",
        "          st.write(cv_review_results_initial_similarity_score)\n",
        "\n",
        "\n",
        "\n",
        "      # NOW LET US GET THE RESULT OF THE CV REVIEW IN TABULAR FORM\n",
        "\n",
        "      cv_review_results_initial_similarity_score_tabular = check_resume_match_with_jd_tabular(job_opening, old_resume)\n",
        "      if cv_review_results_initial_similarity_score_tabular:\n",
        "        if st.button(\"Show Resume Match in Tables\", key = \"resume_match_tabular\"):\n",
        "          st.write(cv_review_results_initial_similarity_score_tabular)\n",
        "\n",
        "\n",
        "\n",
        "      # NOW LET US GET THE SKILL GAPS\n",
        "\n",
        "      # Now Show Skill Gaps\n",
        "      the_identified_skill_gaps = determine_display_skill_gap(job_opening, old_resume)\n",
        "\n",
        "      if the_identified_skill_gaps:\n",
        "        if st.button(\"Show Skill Gaps\", key = \"skill_gaps_key\"):\n",
        "          st.write(f\"The candidate's skills gaps is as below\\n {the_identified_skill_gaps}\")\n",
        "\n",
        "\n",
        "      # NOW LET US DISPLAY SUGGESTIONS\n",
        "\n",
        "      # Display the Suggestion\n",
        "      the_suggestions_for_candidates = give_suggestion(job_opening, the_identified_skill_gaps)\n",
        "\n",
        "      if the_suggestions_for_candidates:\n",
        "        if st.button(\"Show Gap Fixing Suggestions\", key = \"suggestion_key\"):\n",
        "          st.write(f\"The suggestion for the candidate is\\n {the_suggestions_for_candidates}\")\n",
        "\n",
        "\n",
        "    ######THIS IS WHERE I AM PAUSING TO GO AND PRAY#########\n",
        "\n",
        "\n",
        "\n",
        "      # Now to the Most Important Section in this APP: The resume-portion. THIS IS WHERE WE ENCOURAGE THE CANDIDATE TO UPDATE HIS/HER CV\n",
        "\n",
        "      st.write(\"This is where I will explain to the user to manually update the CV\")\n",
        "      st.write(\"\")\n",
        "      st.write(\"\")\n",
        "\n",
        "      # Note that \"resume_portion\" is now replaced with \"previous_jobroles\"\n",
        "\n",
        "      #if previous_jobroles:\n",
        "      if st.session_state.previous_jobroles:\n",
        "          #if st.button(\"Show Resume Portion - Previous Work\", key = \"showresume\"):     # This is the default writting\n",
        "          if st.button(\"Show Resume Portion - Previous Work\", key = \"showresume\"):\n",
        "            #st.write(f\"The candidate's resume portion is\\n {previous_jobroles}\")  # This is the default writting\n",
        "            st.write(f\"The candidate's resume portion is\\n {st.session_state.previous_jobroles}\")   # PUTTING THIS UP TO PERSIST PREVIOUS JOB ROLES Putting this up to persist previous_jobroles\n",
        "            st.write(\" \")\n",
        "            st.write(\" \")\n",
        "            long_text = \"\"\"\n",
        "            Now Copy these Job responsibilities above into your CV. Spread them across the various organizations you have worked.\n",
        "            Try to customize them to the specific project, product development, e.t.c in the individual organization.\n",
        "            The purpose of this is to use this AI as an enabler and not to replace your reasoning and focus on getting the job.\n",
        "            Copying and customized pasting is better than direct copy and pasting. Wisdom is profitable to direct.\n",
        "            Candidate will also have the opportunity to review the generated content this way and reformat/retain their preffered format as necessary\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "            # Displaying the long text using markdown\n",
        "            st.markdown(long_text)\n",
        "            st.write(\"\")\n",
        "\n",
        "\n",
        "      # Now receive the manually updated Resume form the User, but before that, initialize the variable to an empty string to prevent the application throwing up error\n",
        "      if st.session_state.previous_jobroles:\n",
        "        if \"candidate_updated_resume_manual\" not in st.session_state:     # INCLUDED THIS TODAY TO SEE IF IT FIXES THE PERSISTENCE OF THIS VARIABLE\n",
        "\n",
        "          st.session_state.candidate_updated_resume_manual = \"\" # Just to initialize it to nothing\n",
        "        # Now, we advise the User to update their Resume based on the suggestion we gave\n",
        "\n",
        "        with st.sidebar:\n",
        "          st.session_state.candidate_updated_resume_manual = st.text_input(\"Please enter the Resume you have now manually updated with the suggestion provided to you earlier \")\n",
        "        if st.session_state.candidate_updated_resume_manual:\n",
        "          with st.sidebar:\n",
        "            if st.button(\"Click to Manually Update Resume\", key = \"manually_updateresume\") and st.session_state.candidate_updated_resume_manual:\n",
        "              st.success(\"You have now uploaded your manually updated Resume based on the feedback you received\")\n",
        "        # Having done that, the User can compare the Updated Resume Against the Job Description\n",
        "\n",
        "        #if candidate_updated_resume_manual not in st.session_state:   # NEW ADDITION TO PERSIST THE VARIABLE candidate_updated_resume_manual  AVOIDING IT FROM RESTARTING\n",
        "            #st.session_state.candidate_updated_resume_manual = candidate_updated_resume_manual   # NEW ADDITION TO PERSIST THE VARIABLE cv_review_results_initial_similarity_score AVOIDING IT FROM RESTARTING\n",
        "        # if cv_review_results_initial_similarity_score and st.button(\"Click to Manually Update Resume\"): ISOLATING THIS TO SEE WHAT HAPPENS\n",
        "        # DISABLING THE FOUR LINES BELOW TO SEE WHAT HAPPENS WITH THE NEW 3 ACTIVE LINES UP\n",
        "        # if st.button(\"Click to Manually Update Resume\", key = \"manually_updateresume\"):\n",
        "        #   st.session_state.candidate_updated_resume_manual = st.text_input(\"Please enter the Resume you have now manually updated with the suggestion provided to you earlier \")\n",
        "        #   if st.session_state.candidate_updated_resume_manual:\n",
        "        #     st.success(\"You have now uploaded your manually updated Resume based on the feedback you received\")\n",
        "        if st.session_state.candidate_updated_resume_manual:\n",
        "          st.write(f\"Your new resume looks like this \\n {st.session_state.candidate_updated_resume_manual}\")\n",
        "        #the_final_candidate_score_manual = give_candidate_score_after_manual_update(job_opening, st.session_state.candidate_updated_resume_manual) # PREVIOUS TILL YESTERDAY 14/02\n",
        "        if \"the_final_candidate_score_manual\" not in st.session_state:   # NEW ADDITION TO PERSIST THE VARIABLE the_final_candidate_score_manual AVOIDING IT FROM RESTARTING\n",
        "          st.session_state.the_final_candidate_score_manual = \"0%\"\n",
        "        if st.session_state.candidate_updated_resume_manual != \"\" and st.session_state.candidate_updated_resume_manual is not None:  #INTRODUCED THIS THIS MORNING 17 FEB 2024\n",
        "          # st.session_state.the_final_candidate_score_manual = the_final_candidate_score_manual   # NEW ADDITION TO PERSIST THE VARIABLE the_final_candidate_score_manual AVOIDING IT FROM RESTARTING - PREVIOUS TILL YESTERDAY 14/02\n",
        "          st.session_state.the_final_candidate_score_manual = give_candidate_score_after_manual_update(job_opening, st.session_state.candidate_updated_resume_manual)\n",
        "          st.success(\"Yippieee, Your Manually Updated Resume Has Been Uploaded\")\n",
        "          st.session_state.the_final_candidate_score_manual = give_candidate_score_after_manual_update(job_opening, st.session_state.candidate_updated_resume_manual)\n",
        "        else:\n",
        "          st.warning(\"You are Yet to Upload Your Manually Updated Resume, Please Do So When Prompted\")  # INCLUDED THIS MORNING 17/02/2024\n",
        "          st.session_state.the_final_candidate_score_manual = \"\"\n",
        "          st.session_state.the_final_candidate_score_manual = \"I am sorry, I am unable to evaluate at this time\"\n",
        "          st.write(\"Unfortunately, I cannot provide a score until you have uploaded your manually updated Resume. Please look to the left and upload the Resume you have manually updated based on the feedback given and the suggested job responsibilities we supplied to you above.\")\n",
        "        #if final_candidate_score_manual is not None:    # This is the original writting\n",
        "        if st.session_state.the_final_candidate_score_manual: # This is to test if it will suppress the error\n",
        "          if st.button(\"Show Final Score After Manual Update\", key = \"manual_update_score_key\"):\n",
        "            st.write(f\"The final score for the candidate is\\n {st.session_state.the_final_candidate_score_manual}\")\n",
        "\n",
        "\n",
        "\n",
        "        # NOW SHOWING THE UPDATED SCORE AFTER THE MANUAL RESUME UPDATE\n",
        "        # Now let us try and put this in tabular form\n",
        "        if \"the_final_candidate_score_manual_tabular\" not in st.session_state:\n",
        "          st.session_state.the_final_candidate_score_manual_tabular = \"\"\n",
        "          st.session_state.the_final_candidate_score_manual_tabular = give_candidate_score_after_manual_update_tabular(job_opening, st.session_state.candidate_updated_resume_manual)\n",
        "\n",
        "          # Displaying the final score in tabular form\n",
        "\n",
        "          #if final_candidate_score_manual_tabular is not None: # This is the original writting\n",
        "          # if the_final_candidate_score_manual_tabular:  # This is to test if it will suppress the error - JUST INTRODUCED TODAY-14/02\n",
        "          if st.session_state.the_final_candidate_score_manual_tabular is not None:\n",
        "            if st.button(\"Show Final Score After Manual Update in Tables\", key = \"manual_update_score_tabular_key\"):\n",
        "              st.write(f\"The final score for the candidate in tabular form is as below is\\n {st.session_state.the_final_candidate_score_manual_tabular}\")\n",
        "\n",
        "\n",
        "        if \"my_cover_letter\" not in st.session_state:\n",
        "          st.session_state.my_cover_letter = \"\"\n",
        "        if st.session_state.candidate_updated_resume_manual and st.session_state.candidate_updated_resume_manual != None:\n",
        "          st.write(\"You may now generate your Cover Letter now\")\n",
        "          if st.button(\"Generate Cover Letter\") and st.session_state.candidate_updated_resume_manual and st.session_state.candidate_updated_resume_manual != None:\n",
        "            st.session_state.my_cover_letter = generate_cover_letter(job_opening, st.session_state.candidate_updated_resume_manual)\n",
        "            st.success(\"Your Cover Letter is Generated as Below\")\n",
        "            st.write(f\"Your Cover Letter is as given below\\n {st.session_state.my_cover_letter}\")\n",
        "            st.download_button(\"Download Cover Letter\", st.session_state.my_cover_letter.to_doc())  # Trying to see if this will download as word document\n",
        "            st.download_button(\"Download Cover Letter\", st.session_state.my_cover_letter.to_pdf())  # Trying to see if this will download as pdf document\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nuurnc2UlAYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "3facc7af-57bd-489b-dcaa-13308b6cdd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 187) (<ipython-input-2-41abba78cf34>, line 187)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-41abba78cf34>\"\u001b[0;36m, line \u001b[0;32m187\u001b[0m\n\u001b[0;31m    template_9 = \"You are an expert in carefully reviewing/perusing a candidate's Resumes against a job description. Your task is to det\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 187)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# app config\n",
        "%%writefile functionalresumeapp.py\n",
        "\n",
        "import _thread  # Import the _thread module\n",
        "import ssl\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain import PromptTemplate\n",
        "my_openai_key = \"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\"\n",
        "import os\n",
        "import streamlit as st\n",
        "os.environ['OPEN_AI_KEY'] = \"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\"\n",
        "os.environ['OPEN_AI_KEY'] = my_openai_key\n",
        "\n",
        "st.set_page_config(page_title=\"Resume Customization Assistant\", page_icon=\"ðŸ¤–\")\n",
        "st.title(\"Customize Your Resume\")\n",
        "llm = ChatOpenAI(openai_api_key = my_openai_key, temperature = 0) #Commenting it out so that the model is not loaded everytime\n",
        "\n",
        "\n",
        "\n",
        "# THE APPLICATION FUNCTION DEFINITIONS HERE\n",
        "\n",
        "#st.cache_data\n",
        "def get_user_input():\n",
        "  old_resume = st.text_input(\"Please copy and paste your old CV here\")\n",
        "  job_opening = st.text_input(\"Please copy and paste the Job Description of the job being applied for here\")\n",
        "\n",
        "  return old_resume, job_opening\n",
        "\n",
        "@st.cache_data\n",
        "def retrieve_job_extract_and_resume_portion_update_resume_auto(job_opening, dorgsndates, old_resume):\n",
        "    template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an advertised job. Do not (NEVER) make anything up by yourself, STRICTLY FOCUS ON THE DOCUMENTS SHARED WITH YOU TO PROVIDE RESPONSES. If you don't have an answer, make it clear that you don't know. Think step by step, your task is to extract and list each and every (ALL) important job description and skill requirements in this job description\\n{job_description}\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm=llm, prompt=prompt_1, output_key='job_description_extract')\n",
        "\n",
        "\n",
        "    template_2 = \"You are an expert and professional employee actively practicing in your field. Do not (NEVER) make anything up. You MUST provide relevant, valid, creative and effective response even if the document is simply a list of tasks for a given job role. STRICTLY FOCUS ON THE DOCUMENTS SHARED WITH YOU TO PROVIDE RESPONSES. If you dont have an answer, or if the document doesn't seem to be related to a job task/activity, make it clear that you are unable to help and ask the user to supply a list of job tasks. Your task is to develop a list of Job responsibilities from the document below which can be inserted into a Resume as if you are applying for a job. You are to develop/generate a well-detailed, compliant, and matching list of responsibilities so that they describe your previous experiences, knowledge, skills, experiences, and competences matching the details in the document below\\n{job_description_extract}\"\n",
        "    prompt_2 = ChatPromptTemplate.from_template(template_2)\n",
        "    chain_2 = LLMChain(llm=llm, prompt=prompt_2, output_key='resume_portion')\n",
        "\n",
        "    # Now template 4 to Generate the Previous Roles with Dates\n",
        "    template_4 = \"You are a very meticulous and very detailed individual who is an expert in generating/curating a list which narrates your previous responsibilities (ONLY the responsibilities) in the organizations you have previously worked for. You task is to spread these previous responsibilities below, delimited within the asterics(** **), among these recognized organizations (with the respective dates you worked there) {org_and_date}\\n. Ensure you insert each and every responsibility (that were captured) into the list below, but spread them in no particular order among the recognized organizations.  Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. If the document you receive does not have job responsibilities/roles, tell the user that you are unable to assist. LET THE TENSES YOU USE BE PAST TENSES (e.g 'Supported the team that delivered the Cloud Migration project using AWS services for Access Bank, Lagos') The responsibilities are here below:\\n**{resume_portion}** \"\n",
        "    # If the supplied document does not look like a Resume or CV, tell the user to upload a valid Resume/CV, without which you are unable to assist.\n",
        "    prompt_4 = ChatPromptTemplate.from_template(template_4)\n",
        "    chain_4 = LLMChain(llm = llm, prompt=prompt_4, output_key='previous_roles_with_dates')\n",
        "\n",
        "    # template 5 that Generates an Updated Resume Automatically - Not Recommended as we want the User to remain in Control the narrative that goes into their Resume. LLM today are still grossly INDETERMINATE\n",
        "    # and can generate non-representative description about you. Your profile is in your hands\n",
        "\n",
        "    template_5 = \"You are great at updating and customizing your old resume to fit a new job you are applying for. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. You put all your strong points forward. You are very known as very spot-on and competent in interlacing, interweaving and integrating your previous and present job roles/responsibilities into your old resume so that you can create an updated Resume to make it very compliant to the demands of a new job you are applying for. You have achieved great successes in doing this in the past. You are to ADD, integrate, digest, interlace, interweave ALL these previous roles below \\n {previous_roles_with_dates}\\n into the old resume below delimited in square brackets below so that a single, whole and robust (heterogenous mix of both contents/documents) is generated as a result. \\nUse same formatting style, font type/size, bullet types, and formatting layout present in the old resume. In the resulting updated Resume, ensure that the responsibilities in the MOST RECENT COMPANY/ORGANIZATION are WRITTEN IN PRESENT CONTINUOUS TENSES. ALL other Job responsibilites in other WORKPLACES/ORGANIZATIONS are written in PAST TENSES. NEVER repeat any responsibility or sentence in the updated resume. The old resume is here below:\\n [{old_cv}]\" # WITHOUT LOSING ANY DETAILS IN THE JOB ROLE AND RESPONSIBILITIES PRESENT IN THE OLD RESUME,\n",
        "    prompt_5 = ChatPromptTemplate.from_template(template_5)\n",
        "    chain_5 = LLMChain(llm = llm, prompt=prompt_5, output_key='updated_resume')\n",
        "\n",
        "    # Now, trying to generate the results of developing the updated resume\n",
        "\n",
        "    updated_resume_chain = SequentialChain(\n",
        "        chains = [chain_1, chain_2,  chain_4, chain_5],\n",
        "        input_variables = ['job_description', 'org_and_date', 'old_cv'],\n",
        "        output_variables = ['job_description_extract', 'resume_portion', 'previous_roles_with_dates', 'updated_resume'],\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    updated_resume_results = updated_resume_chain({\"job_description\": job_opening, 'org_and_date' : dorgsndates, \"old_cv\": old_resume, })\n",
        "\n",
        "    important_jd = updated_resume_results[\"job_description_extract\"]\n",
        "    previous_jobroles = updated_resume_results[\"resume_portion\"]\n",
        "    previous_roles_n_dates = updated_resume_results[\"previous_roles_with_dates\"]\n",
        "    auto_updated_resume = updated_resume_results[\"updated_resume\"]\n",
        "\n",
        "    return important_jd, previous_jobroles, previous_roles_n_dates, auto_updated_resume\n",
        "\n",
        "\n",
        "@st.cache_data\n",
        "def retrieve_previous_organizations_and_dates(old_resume):\n",
        "  # Now template 3 goes in\n",
        "    dorgsndates = \"\"  #  Initiating this to an empty string as it kept halucinating\n",
        "    template_3 = \"\"\"You are an expert and professional employee actively practicing in your field and have worked with a few organizations. You are proud of these organizations and the periods you worked with each of these organizations. Do not (NEVER) make anything up, do not list any arbitrary company/organization except the user supplies such for you. If you dont have an answer, make it clear that you dont know. Your task is to recognize and list/write out these individual organizations you have worked with previously (entity recognition) including the dates you worked with them based on your old resume detailed here\\n {old_cv}. Return only the details required and no other phrase or sentence. Example of a response is \"1. Jaguar Land Rover, Gaydon UK\n",
        "    - Position: AI Consultant Cum Scrum Master\n",
        "        - Dates: Nov 2022 - Present \"\n",
        "    \"\"\"\n",
        "    prompt_3 = ChatPromptTemplate.from_template(template_3)\n",
        "    chain_3 = LLMChain(llm = llm, prompt=prompt_3)   # removed output_key='organization_and_dates')\n",
        "\n",
        "    # Now the Organizations the Candidate has previously worked for and dates goes here:\n",
        "\n",
        "    dorgsndates = chain_3.run(old_resume)  # dorgsndates is short for \"d_organizations_and_dates ()\" We run this chain to retrieve the organizations worked with and the dates.\n",
        "    # dorgsndates\n",
        "\n",
        "    st.write(\"This is where I will explain that the application will list the previous place you have worked\")\n",
        "    st.write(\"\")\n",
        "    st.write(\"\")\n",
        "    # This will check the previous companies that the candidate had worked with previously\n",
        "    #\n",
        "    return dorgsndates\n",
        "\n",
        "@st.cache_data\n",
        "def check_resume_match_with_jd(job_opening, old_resume):\n",
        "\n",
        "    template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an an advertized job. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description\\n{job_description}\"\n",
        "    # template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an an advertized job. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description below (adding other relevant key requirements, expertise, skills and  experiences that may be required for the role/job description) \\n{job_description}\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm = llm, prompt=prompt_1, output_key='job_description_extract')\n",
        "\n",
        "\n",
        "    template_6 = \"You are an expert in reviewing candidates' resume against job description to shortlist only qualified candidates whose Resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Your expertise is top-notch in the careful perusal of the received Resume comparing it with the job description received from the hiring organization with the intention to determine the candidate's fit/qualification for the job. Let us think step-by-step. Be logical and do not rush to an answer but do review and analyze the entire documents shared with you properly. Your task is to come up with a similarity score (on a scale of 0-100%) after comparing this job description {job_description_extract} with the candidate CV here below\\n{old_cv}\"\n",
        "    prompt_6 = ChatPromptTemplate.from_template(template_6)\n",
        "    chain_6 = LLMChain(llm = llm, prompt=prompt_6, output_key='initial_similarity_score')\n",
        "\n",
        "    cv_review_chain = SequentialChain(\n",
        "        chains = [chain_1, chain_6],\n",
        "        input_variables = ['job_description', 'old_cv'],\n",
        "        output_variables = ['initial_similarity_score'],\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    cv_review_results = cv_review_chain({\"job_description\" : job_opening, \"old_cv\": old_resume})\n",
        "    return cv_review_results['initial_similarity_score']\n",
        "\n",
        "@st.cache_data\n",
        "def check_resume_match_with_jd_tabular(job_opening, old_resume):\n",
        "   # Generating Resume match in Tabular Form\n",
        "\n",
        "    template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an an advertized job. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description\\n{job_description}\"\n",
        "    # template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an an advertized job. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description below (adding other relevant key requirements, expertise, skills and  experiences that may be required for the role/job description) \\n{job_description}\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm = llm, prompt=prompt_1, output_key='job_description_extract')\n",
        "\n",
        "\n",
        "    template_6a = \"You are an expert in reviewing candidates' resume against job description to shortlist only qualified candidates whose Resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Your expertise is top-notch in the careful perusal of the received Resume comparing it with the job description received from the hiring organization with the intention to determine the candidate's fit/qualification for the job. Be logical and do not rush to an answer but do review and analyze the entire documents shared with you properly. Your task is to come up with a similarity score (expressing it as an OVERALL SUMMARY/FINAL similarity score )on a scale of 0-100% ONLY IN TABULATED FORMAT. Come up with a well-formatted HTML table for the final average % after determining the individual percentages for each assessement area after comparing this job description {job_description_extract} with the candidate CV here below\\n{old_cv}\"\n",
        "    prompt_6a = ChatPromptTemplate.from_template(template_6a)\n",
        "    chain_6a = LLMChain(llm = llm, prompt=prompt_6a, output_key='initial_similarity_score_tabulated')\n",
        "\n",
        "    cv_review_chain_a = SequentialChain(\n",
        "        chains = [chain_1, chain_6a],\n",
        "        input_variables = ['job_description', 'old_cv'],\n",
        "        output_variables = ['initial_similarity_score_tabulated'],\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    cv_review_results_tabulated = cv_review_chain_a({\"job_description\" : job_opening, \"old_cv\": old_resume})\n",
        "    return cv_review_results_tabulated['initial_similarity_score_tabulated']\n",
        "\n",
        "@st.cache_data\n",
        "def determine_display_skill_gap(job_opening, old_resume):\n",
        "    # Now Giving Feedback on Skill Gaps Based on the Relevance/Match of the Job Description and Candidate's Resume\n",
        "\n",
        "    template_1 = \"You are a very meticulous and detailed professional who is able to read in-between the lines and comprehend all the necessary job requirements listed in an advertised job. Do not (NEVER) make anything up. If you don't have an answer, make it clear that you don't know. Think step by step, your task is to extract and list each and every (ALL) important job description and requirements in this job description\\n{job_description}\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm=llm, prompt=prompt_1, output_key='job_description_extract')\n",
        "\n",
        "\n",
        "    template_7 = \"You are an expert in reviewing candidate's resume against job description to shortlist only qualified candidates whose resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. THERE IS NO NEED for the candidate to list specific examples for each area of competence, experience or skills (a simple mentioning of the requirements listed in the job description is sufficient to qualify them for shortlisting). DO NOT make any issue against a candidate who didnt provide specific examples of skills, competencies or experiences. Only discuss gaps that were not mentioned at all. Your task is to come up with a detailed list of the gaps in the candidate's skills, experiences and competencies after comparing this job description {job_description_extract} with the candidate CV here below\\n{old_cv}\"\n",
        "    prompt_7 = ChatPromptTemplate.from_template(template_7)\n",
        "    chain_7 = LLMChain(llm = llm, prompt=prompt_7, output_key='skill_gaps')\n",
        "\n",
        "    skill_gaps_chain = SequentialChain(\n",
        "        chains = [chain_1, chain_7],\n",
        "        input_variables = ['job_description', 'old_cv'],\n",
        "        output_variables = ['job_description_extract', 'skill_gaps'],\n",
        "        verbose=True\n",
        "        )\n",
        "\n",
        "    skill_gaps_results = skill_gaps_chain({\"job_description\" : job_opening, \"old_cv\": old_resume})\n",
        "\n",
        "    identified_skill_gaps = skill_gaps_results['skill_gaps']\n",
        "    return identified_skill_gaps\n",
        "\n",
        "\n",
        "@st.cache_data\n",
        "def give_suggestion(job_opening, identified_skill_gaps):\n",
        "  # Now, Let us Give Suggestions to the Candidate\n",
        "\n",
        "    template_8 = \"You are an expert job-haunting coach who is great and has achieved repeated successes in coaching and preparing candidates for job interviews, based on their skill gaps. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. You usually provide both short term and long term suggestions for the candidates to ace at job interviews. The short term suggestions and advice are what the candidate can do to brush up for the coming interviews. Given that they are applying for the job role with the job description here\\n{job_description}, you are to GENERATE A LIST of SHORT TERM and LONG TERM suggestions for this candidate after you have completed a thorough perusal of their identified skill gaps here below\\n{skill_gaps}\"\n",
        "    prompt_8 = ChatPromptTemplate.from_template(template_8)\n",
        "    chain_8 = LLMChain(llm = llm, prompt=prompt_8, output_key='suggestions')\n",
        "\n",
        "    suggestion_for_candidate = chain_8.run({'job_description': job_opening, 'skill_gaps': identified_skill_gaps})\n",
        "    return suggestion_for_candidate\n",
        "\n",
        "##### THIS IS THE LAST TWO FUNCTIONS TO USE #######\n",
        "\n",
        "#@st.cache_data  # Trying to make sure this re-runs so that when users updates the CV, this is updated.\n",
        "def give_candidate_score_after_manual_update(job_opening, candidate_updated_resume_manual):\n",
        "    #template_9 = \"You are an expert in reviewing candidates' Resumes against a job description to shortlist only qualified candidates whose Resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Your expertise is top-notch in the careful perusal of the received Resume and comparing it with the job description received from the hiring organization. Your task is to determine the candidate's fit/qualification for the job. You are to come up with a similarity score (on a scale of 0-100%) after comparing this job description {job_description} with the candidate's Resume here below\\n{updated_resume}\"\n",
        "    template_9 = \"You are an expert in carefully reviewing/perusing a candidate's Resumes against a job description. Your task is to determine what percentage of the details/requirements the Job Description is reflected/addressed/captured in the Resume. You are to come up with a score on a scale of 0% to 100% based on this assessment. If all of the Job Description is included in the Resume, then the score is 100%, if none of the Job Description is contained in the Resume, then score is 0% - others are in-between. Think Step by Step and logically. DO NOT make anything up, ONLY USE THE DOCUMENTS PROVIDED TO YOU...do not use generic documents. YOU MUST CAREFULLY Read through the document from the beginning to the end ensuring you match context for context, any error in % mapping will be severely dealt with, so you must be thorough in your assessment and evaluation.. If the document you are comparing the Job Description with doesn't look a Resume, let the User understand this and let them know you cannot proceed until a valid Resume is supplied. This is the Job Description \\n {job_description} and the Resume is here below\\n\\n{updated_resume}\"\n",
        "    # You are an expert at generating a score of how well a resume matches a given job description, capturing the relevant keywords and the important job requirements detailed in the Job Description. You ALWAYS provide a score of how well the resume captures and matches the important job needs, skill requirements, experience and specific technologies that are documented in the Job Description. Confirm if alll the important details of this job description {job description} are covered in this Job resume {\"Manually Updated Resume\"}\n",
        "    prompt_9 = ChatPromptTemplate.from_template(template_9)\n",
        "    chain_9 = LLMChain(llm = llm, prompt=prompt_9, output_key='final_similarity_score_manual')\n",
        "\n",
        "    final_candidate_score_manual= chain_9.run({'job_description': job_opening, 'updated_resume': candidate_updated_resume_manual})\n",
        "    return final_candidate_score_manual\n",
        "\n",
        "@st.cache_data\n",
        "def give_candidate_score_after_manual_update_tabular(job_opening, candidate_updated_resume_manual):\n",
        "    template_9a = \"You are an expert in reviewing a candidate's Resumes against a job description. DO NOT make anything up, ONLY USE THE DOCUMENTS PROVIDED TO YOU...do not use generic documents and compare context for context. If you dont have an answer, make it clear that you dont know. Your task is to determine what percentage of the Job Description is reflected in the Resume - You are to come up with a percentage score on a scale of 0% to 100%. If all of the Job Description is included in the Resume, then the score is 100%, if none of the Job Description is contained in the Resume, then score is 0% - others are in-between. YOU SHOULD RETURN YOUR FINDINGS IN TABULAR FORM. This is the Job Description \\n {job_description} and the Resume is here below\\n\\n{updated_resume}\"\n",
        "    #template_9a = \"You are an expert in reviewing candidates' Resumes against a job description to shortlist only qualified candidates whose Resume map strongly to the requirements of the job being advertized. Do not (NEVER) make anything up. If you dont have an answer, make it clear that you dont know. Your expertise is top-notch in the careful perusal of the received Resume and comparing it with the job description received from the hiring organization. Your task is to determine the candidate's fit/qualification for the job. You are to come up with a similarity score (on a scale of 0-100%) RETURNED IN TABULAR FORM after comparing this job description {job_description} with the candidate's Resume here below\\n{updated_resume}\"\n",
        "    prompt_9a = ChatPromptTemplate.from_template(template_9a)\n",
        "    chain_9a = LLMChain(llm = llm, prompt=prompt_9a, output_key='final_similarity_score_manual_tabular')\n",
        "\n",
        "    final_candidate_score_manual_tabular = chain_9a.run({'job_description': job_opening, 'updated_resume': candidate_updated_resume_manual}) # Consider Changing the documents- job_opening to important_jd or previous_jobroles\n",
        "    return final_candidate_score_manual_tabular\n",
        "\n",
        "@st.cache_data\n",
        "def generate_cover_letter(job_opening, candidate_updated_resume_manual):\n",
        "  template_10 = \"\"\" You are a professional consultant known for generating very captivating and effective Cover Letters when supplied with a Job Description.\n",
        "  You creatively use the combination of the received Job Description and your Resume to generate a top-notch Cover Letter that is irresistible, well matched to the Job Description and aligned with your Resume.\n",
        "  Given the Job Description/Requirements delimited below by double angle brackets, and your Resume delimited by triple asterisk delimiters in the lines below, your task is to generate a Cover Letter.\n",
        "  The Cover Letter should portray you as best suited for the position in the JOb Description, showing your interest in the job, and presenting your skills, certifications, education and experiences (based on your Resume and Job Description) effectively in short but impactful/catchy paragraphs.\n",
        "  The Cover Letter must portray you as being self-motivated, a good leader and a well-organized individual. It must also reflect you as meeting/surpassing the requirements in the Job Description\n",
        "  <<{job_descrip}>>\n",
        "  ***{your_resume}***\n",
        "  \"\"\"\n",
        "  prompt_10 = ChatPromptTemplate.from_template(template_10)\n",
        "  chain_10 = LLMChain(llm = llm, prompt=prompt_10, output_key='cover_letter')\n",
        "\n",
        "  cover_letter = chain_10.run({'job_descrip': job_opening, 'your_resume': candidate_updated_resume_manual}) #\n",
        "  return cover_letter\n",
        "\n",
        "## THE MAIN PROGRAM CALLS HERE\n",
        "\n",
        "# NOW GOING INTO THE CODE PROPER\n",
        "\n",
        "def main():\n",
        "\n",
        "  with st.sidebar:\n",
        "    st.header(\"Your Documents Here\")\n",
        "    st.markdown(\"## Usage of the App\")\n",
        "    st.write(\"**How to Use**\")\n",
        "    st.write(\"These are the simple ways of using the App.........\")\n",
        "    st.write(\" \")\n",
        "    st.divider()\n",
        "    old_resume, job_opening = get_user_input()\n",
        "    st.markdown(\"Perhaps Goes In an Expander - Click to Read More\")\n",
        "    # with st.expander(\"Intent of the Application....Click to Read More\"):\n",
        "    #   st.write(\"\"\"\n",
        "    #             Note that the intent of this Resume Assistant is not to aid you in telling lies about your abilities, competence, skills and/or experiences, rather it helps you articulate and emphasize your professional skills, tailoring your resume to the requirements of the job, (which we assume you meet but unable to succinctly put together at the same speed of this application) and making sure that the hiring/hr managers select your Resume as qualified for the advertised role. Tailoring your resume takes time and effort but itâ€™s definitely worth it â€“ this is the whole essence of this Assistant!\n",
        "    #   \"\"\")\n",
        "    # with st.expander(\"Click Here to Read More\"):\n",
        "    #   st.write(\"\"\"\n",
        "    #   Ensure that the suggestions given to you are properly worded to your taste and inserted as close as possible to the top of the Resume. This could mean trying to have these suggestions included in your most recent job role.\n",
        "    #   You are responsible for not telling a lie about your capabilities and abilities. Ensure that the position/location you insert a particular suggested job responsibilities aligns and fits well with the Job role/Organization\n",
        "    #   Use the right tense. It is suggested to use present continous tense for your present role and active past tense for your past roles and responsibilities.\n",
        "    #   Infuse the generated job responsibilities intuitively into your Resume such that there is a homogenous mix of the two. Interlace and interweave them into your existing Resume.\n",
        "    #   Make sure you include other required expert knowledge, certifications, experiences, skills and required competencies the Resume.\n",
        "    #   Use the relevant job titles, the name of the companies and dates of employments in your Resume. Clear headlines depicting these makes your Resume to be more ATS friendly.\n",
        "    #   The responsibility of review of the suggested responsibilities lies with you. You should ensure that the generated suggestions are infused, spread and distributed within your present Resume in a coherent manner while maintain a professional, reasonable and logical flow so as to reflect that you own the experiences, competencies, and skills in the resultant Customized Resume .\n",
        "    #   \"\"\")\n",
        "    # st.write(\"\"\" Top Tips\n",
        "    # Use the top half of your resumeâ€™s first page.\n",
        "    # Together with your contact information and Resume Summary, your job description is one of the first things recruiters and hiring managers read in your resume.\n",
        "    # Since recruiters only spend around seven seconds before they either rule you out or move you to the next round, it is imperative that you put your most attractive job roles and responsibilities (that maps well to the advertised job description) in the top half section of your resume.\n",
        "\n",
        "    # \"\"\")\n",
        "\n",
        "  if old_resume is None or old_resume == \"\":\n",
        "      st.info(\"Please paste your present Resume into the side-bar <---\")\n",
        "\n",
        "  if job_opening is None or job_opening == \"\":\n",
        "      st.info(\"Please paste the Job Description into the side-bar <---\")\n",
        "\n",
        "  if old_resume and job_opening:\n",
        "      # NOW UNTO THE PREVIOUS ORGANIZATIONS AND DATES\n",
        "      dorgsndates = retrieve_previous_organizations_and_dates(old_resume)\n",
        "      if st.button(\"Show Previous Companies\", key = \"show_prev\"):\n",
        "        st.write(f\"The organization the candidates has worked with before is\\n {dorgsndates}\")\n",
        "\n",
        "\n",
        "      # For Chain 1, 2 4 and 5\n",
        "\n",
        "      important_jd, previous_jobroles, previous_roles_n_dates, auto_updated_resume = retrieve_job_extract_and_resume_portion_update_resume_auto(job_opening, dorgsndates, old_resume)\n",
        "\n",
        "      # st.write(\"This is where I will explain the process of automatically updating the resume\")\n",
        "      # st.write(\"\")\n",
        "      # st.write(\"\")\n",
        "\n",
        "      # #if updated_resume_results is not None and updated_resume_results != \"\":  # This is the original write-up\n",
        "      # if updated_resume_results and st.button(\"Show Previous Companies\"):  # Checking if this will help with keeping the one below it quiet\n",
        "      #   if st.button(\"Show Updated Resume\", key = \"updated resume\"):\n",
        "      #     st.write(f\"The updated Resume is\\n {candidate_updated_resume}\")\n",
        "\n",
        "    # USING FORMS FOR THESE FOUR OUTPUTS\n",
        "\n",
        "      if previous_jobroles not in st.session_state:        # ADDED THIS TO KEEP previous_jobroles PERSISTENT\n",
        "        st.session_state.previous_jobroles = previous_jobroles  # SAME HERE\n",
        "\n",
        "      with st.form(\"What to Retrieve\"):\n",
        "        doc_to_retrieve = st.selectbox(\"Document to Retrieve\", [\"The Job Description Extract\", \"Previous Job Roles\", \"Previous Job Roles with Dates\", \"Automated Generated Resume\"], index=1)\n",
        "        submit_button = st.form_submit_button(\"Retrieve\")\n",
        "\n",
        "        if submit_button and (doc_to_retrieve == \"The Job Description Extract\"):\n",
        "          st.write(important_jd)\n",
        "\n",
        "        elif submit_button and (doc_to_retrieve == \"Previous Job Roles\"):\n",
        "          st.write(st.session_state.previous_jobroles) # THIS IS NOW UPGRADED ALSO\n",
        "\n",
        "        elif submit_button and (doc_to_retrieve == \"Previous Job Roles with Dates\"):\n",
        "          st.write(previous_roles_n_dates)\n",
        "\n",
        "        elif submit_button and (doc_to_retrieve == \"Automated Generated Resume\"):\n",
        "          st.write(auto_updated_resume)\n",
        "\n",
        "\n",
        "      # NOW LET US GET THE RESULT OF THE CV REVIEW\n",
        "\n",
        "      cv_review_results_initial_similarity_score = check_resume_match_with_jd(job_opening, old_resume)\n",
        "\n",
        "      st.write(\"This is where I will explain what happens here\")\n",
        "      st.write(\"\")\n",
        "      st.write(\"\")\n",
        "\n",
        "      if cv_review_results_initial_similarity_score:\n",
        "        if st.button(\"Show Resume Match\", key = \"resume_match\"):\n",
        "          st.write(cv_review_results_initial_similarity_score)\n",
        "\n",
        "\n",
        "\n",
        "      # NOW LET US GET THE RESULT OF THE CV REVIEW IN TABULAR FORM\n",
        "\n",
        "      cv_review_results_initial_similarity_score_tabular = check_resume_match_with_jd_tabular(job_opening, old_resume)\n",
        "      if cv_review_results_initial_similarity_score_tabular:\n",
        "        if st.button(\"Show Resume Match in Tables\", key = \"resume_match_tabular\"):\n",
        "          st.write(cv_review_results_initial_similarity_score_tabular)\n",
        "\n",
        "\n",
        "\n",
        "      # NOW LET US GET THE SKILL GAPS\n",
        "\n",
        "      # Now Show Skill Gaps\n",
        "      the_identified_skill_gaps = determine_display_skill_gap(job_opening, old_resume)\n",
        "\n",
        "      if the_identified_skill_gaps:\n",
        "        if st.button(\"Show Skill Gaps\", key = \"skill_gaps_key\"):\n",
        "          st.write(f\"The candidate's skills gaps is as below\\n {the_identified_skill_gaps}\")\n",
        "\n",
        "\n",
        "      # NOW LET US DISPLAY SUGGESTIONS\n",
        "\n",
        "      # Display the Suggestion\n",
        "      the_suggestions_for_candidates = give_suggestion(job_opening, the_identified_skill_gaps)\n",
        "\n",
        "      if the_suggestions_for_candidates:\n",
        "        if st.button(\"Show Gap Fixing Suggestions\", key = \"suggestion_key\"):\n",
        "          st.write(f\"The suggestion for the candidate is\\n {the_suggestions_for_candidates}\")\n",
        "\n",
        "\n",
        "    ######THIS IS WHERE I AM PAUSING TO GO AND PRAY#########\n",
        "\n",
        "\n",
        "\n",
        "      # Now to the Most Important Section in this APP: The resume-portion. THIS IS WHERE WE ENCOURAGE THE CANDIDATE TO UPDATE HIS/HER CV\n",
        "\n",
        "      st.write(\"This is where I will explain to the user to manually update the CV\")\n",
        "      st.write(\"\")\n",
        "      st.write(\"\")\n",
        "\n",
        "      # Note that \"resume_portion\" is now replaced with \"previous_jobroles\"\n",
        "\n",
        "      #if previous_jobroles:\n",
        "      if st.session_state.previous_jobroles:\n",
        "          #if st.button(\"Show Resume Portion - Previous Work\", key = \"showresume\"):     # This is the default writting\n",
        "          if st.button(\"Show Resume Portion - Previous Work\", key = \"showresume\"):\n",
        "            #st.write(f\"The candidate's resume portion is\\n {previous_jobroles}\")  # This is the default writting\n",
        "            st.write(f\"The candidate's resume portion is\\n {st.session_state.previous_jobroles}\")   # PUTTING THIS UP TO PERSIST PREVIOUS JOB ROLES Putting this up to persist previous_jobroles\n",
        "            st.write(\" \")\n",
        "            st.write(\" \")\n",
        "            long_text = \"\"\"\n",
        "            Now Copy these Job responsibilities above into your CV. Spread them across the various organizations you have worked.\n",
        "            Try to customize them to the specific project, product development, e.t.c in the individual organization.\n",
        "            The purpose of this is to use this AI as an enabler and not to replace your reasoning and focus on getting the job.\n",
        "            Copying and customized pasting is better than direct copy and pasting. Wisdom is profitable to direct.\n",
        "            Candidate will also have the opportunity to review the generated content this way and reformat/retain their preffered format as necessary\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "            # Displaying the long text using markdown\n",
        "            st.markdown(long_text)\n",
        "            st.write(\"\")\n",
        "\n",
        "\n",
        "      # Now receive the manually updated Resume form the User, but before that, initialize the variable to an empty string to prevent the application throwing up error\n",
        "      if st.session_state.previous_jobroles:\n",
        "        if \"candidate_updated_resume_manual\" not in st.session_state:     # INCLUDED THIS TODAY TO SEE IF IT FIXES THE PERSISTENCE OF THIS VARIABLE\n",
        "\n",
        "          st.session_state.candidate_updated_resume_manual = \"\" # Just to initialize it to nothing\n",
        "        # Now, we advise the User to update their Resume based on the suggestion we gave\n",
        "\n",
        "        with st.sidebar:\n",
        "          st.session_state.candidate_updated_resume_manual = st.text_input(\"Please enter the Resume you have now manually updated with the suggestion provided to you earlier \")\n",
        "        if st.session_state.candidate_updated_resume_manual:\n",
        "          with st.sidebar:\n",
        "            if st.button(\"Click to Manually Update Resume\", key = \"manually_updateresume\") and st.session_state.candidate_updated_resume_manual:\n",
        "              st.success(\"You have now uploaded your manually updated Resume based on the feedback you received\")\n",
        "        # Having done that, the User can compare the Updated Resume Against the Job Description\n",
        "\n",
        "        #if candidate_updated_resume_manual not in st.session_state:   # NEW ADDITION TO PERSIST THE VARIABLE candidate_updated_resume_manual  AVOIDING IT FROM RESTARTING\n",
        "            #st.session_state.candidate_updated_resume_manual = candidate_updated_resume_manual   # NEW ADDITION TO PERSIST THE VARIABLE cv_review_results_initial_similarity_score AVOIDING IT FROM RESTARTING\n",
        "        # if cv_review_results_initial_similarity_score and st.button(\"Click to Manually Update Resume\"): ISOLATING THIS TO SEE WHAT HAPPENS\n",
        "        # DISABLING THE FOUR LINES BELOW TO SEE WHAT HAPPENS WITH THE NEW 3 ACTIVE LINES UP\n",
        "        # if st.button(\"Click to Manually Update Resume\", key = \"manually_updateresume\"):\n",
        "        #   st.session_state.candidate_updated_resume_manual = st.text_input(\"Please enter the Resume you have now manually updated with the suggestion provided to you earlier \")\n",
        "        #   if st.session_state.candidate_updated_resume_manual:\n",
        "        #     st.success(\"You have now uploaded your manually updated Resume based on the feedback you received\")\n",
        "        if st.session_state.candidate_updated_resume_manual:\n",
        "          st.write(f\"Your new resume looks like this \\n {st.session_state.candidate_updated_resume_manual}\")\n",
        "        #the_final_candidate_score_manual = give_candidate_score_after_manual_update(job_opening, st.session_state.candidate_updated_resume_manual) # PREVIOUS TILL YESTERDAY 14/02\n",
        "        if \"the_final_candidate_score_manual\" not in st.session_state:   # NEW ADDITION TO PERSIST THE VARIABLE the_final_candidate_score_manual AVOIDING IT FROM RESTARTING\n",
        "          st.session_state.the_final_candidate_score_manual = \"0%\"\n",
        "        if st.session_state.candidate_updated_resume_manual != \"\" and st.session_state.candidate_updated_resume_manual is not None:  #INTRODUCED THIS THIS MORNING 17 FEB 2024\n",
        "          # st.session_state.the_final_candidate_score_manual = the_final_candidate_score_manual   # NEW ADDITION TO PERSIST THE VARIABLE the_final_candidate_score_manual AVOIDING IT FROM RESTARTING - PREVIOUS TILL YESTERDAY 14/02\n",
        "          st.session_state.the_final_candidate_score_manual = give_candidate_score_after_manual_update(job_opening, st.session_state.candidate_updated_resume_manual)\n",
        "          st.success(\"Yippieee, Your Manually Updated Resume Has Been Uploaded\")\n",
        "          st.session_state.the_final_candidate_score_manual = give_candidate_score_after_manual_update(job_opening, st.session_state.candidate_updated_resume_manual)\n",
        "        else:\n",
        "          st.warning(\"You are Yet to Upload Your Manually Updated Resume, Please Do So When Prompted\")  # INCLUDED THIS MORNING 17/02/2024\n",
        "          st.session_state.the_final_candidate_score_manual = \"\"\n",
        "          st.session_state.the_final_candidate_score_manual = \"I am sorry, I am unable to evaluate at this time\"\n",
        "          st.write(\"Unfortunately, I cannot provide a score until you have uploaded your manually updated Resume. Please look to the left and upload the Resume you have manually updated based on the feedback given and the suggested job responsibilities we supplied to you above.\")\n",
        "        #if final_candidate_score_manual is not None:    # This is the original writting\n",
        "        if st.session_state.the_final_candidate_score_manual: # This is to test if it will suppress the error\n",
        "          if st.button(\"Show Final Score After Manual Update\", key = \"manual_update_score_key\"):\n",
        "            st.write(f\"The final score for the candidate is\\n {st.session_state.the_final_candidate_score_manual}\")\n",
        "\n",
        "\n",
        "\n",
        "        # NOW SHOWING THE UPDATED SCORE AFTER THE MANUAL RESUME UPDATE\n",
        "        # Now let us try and put this in tabular form\n",
        "        if \"the_final_candidate_score_manual_tabular\" not in st.session_state:\n",
        "          st.session_state.the_final_candidate_score_manual_tabular = \"\"\n",
        "          st.session_state.the_final_candidate_score_manual_tabular = give_candidate_score_after_manual_update_tabular(job_opening, st.session_state.candidate_updated_resume_manual)\n",
        "\n",
        "          # Displaying the final score in tabular form\n",
        "\n",
        "          #if final_candidate_score_manual_tabular is not None: # This is the original writting\n",
        "          # if the_final_candidate_score_manual_tabular:  # This is to test if it will suppress the error - JUST INTRODUCED TODAY-14/02\n",
        "          if st.session_state.the_final_candidate_score_manual_tabular is not None:\n",
        "            if st.button(\"Show Final Score After Manual Update in Tables\", key = \"manual_update_score_tabular_key\"):\n",
        "              st.write(f\"The final score for the candidate in tabular form is as below is\\n {st.session_state.the_final_candidate_score_manual_tabular}\")\n",
        "\n",
        "\n",
        "        if \"my_cover_letter\" not in st.session_state:\n",
        "          st.session_state.my_cover_letter = \"\"\n",
        "        if st.session_state.candidate_updated_resume_manual and st.session_state.candidate_updated_resume_manual != None:\n",
        "          st.write(\"You may now generate your Cover Letter now\")\n",
        "          if st.button(\"Generate Cover Letter\") and st.session_state.candidate_updated_resume_manual and st.session_state.candidate_updated_resume_manual != None:\n",
        "            st.session_state.my_cover_letter = generate_cover_letter(job_opening, st.session_state.candidate_updated_resume_manual)\n",
        "            st.success(\"Your Cover Letter is Generated as Below\")\n",
        "            st.write(f\"Your Cover Letter is as given below\\n {st.session_state.my_cover_letter}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW4Ft7IE4ymG",
        "outputId": "df4f0fb0-2f0a-43b9-9c8d-4c9911002d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing functionalresumeapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run functionalresumeapp.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "xDOgKzvQlAPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hl7tZ5o6lAMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUERY YOUR (OR A PARTICULAR) YOUTUBE VIDEO\n",
        "### (DOESN'T GO A BIT BEYOND WHAT YOU HAVE IN YOUR VIDEO, NOT EVEN THE BASE KNOWLEDGE OF THE LLM IS USED TO PROVIDE ANSWERS)"
      ],
      "metadata": {
        "id": "eq6PQO2ChASy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain streamlit openai youtube-transcript-api chromadb tiktoken"
      ],
      "metadata": {
        "id": "N9dYoC6Pg6qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ytqueryapp.py\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os\n",
        "import streamlit as st\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "from langchain import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "\n",
        "# Set OpenAI key\n",
        "my_openai_key = \"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\"\n",
        "os.environ['OPEN_AI_KEY'] = my_openai_key\n",
        "# MAKE SURE YOU SET TEMPERATURE TO \"0\"\n",
        "# Create OpenAI instance\n",
        "llm = OpenAI(openai_api_key=my_openai_key, temperature=0)\n",
        "# I can introduce Google Gemini Pro here if I dont want to incur cost and have more context length so that I can use k=4\n",
        "# I introduce the code below:\n",
        "# Thankfully, Gemini is compatible with langchain and can be used without any significant change\n",
        "# import getpass\n",
        "# import os\n",
        "# !pip install --upgrade --quiet  langchain-google-genai pillow\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key = \"AIzaSyBtmPCYd1Zwf7uJIv4mB2ISngAJGqcQ58c\")\n",
        "# result = llm.invoke(\"Tell me about Nigeria, in nothing less than 3000 words. Write it in ryhmes\")\n",
        "# print(result.content)\n",
        "\n",
        "\n",
        "# Display the Page Title\n",
        "st.title('Youtube QnA')\n",
        "\n",
        "# Obtain user input or specify a value for prompt\n",
        "my_url = st.text_input(\"Enter YouTube URL\")\n",
        "\n",
        "if my_url:\n",
        "    query = st.text_input(\"Enter Your Question Here\", key = \"query_key\")\n",
        "    #query = \"\".join([\"Without assumptions or making anything up and according to the video transcript, what did the speaker say about \", query])\n",
        "    #query = \"\".join([\"According to the video transcript based on what the speaker said, \", query]) # Reframing the question\n",
        "    loader = YoutubeLoader.from_youtube_url(my_url, add_video_info=False)\n",
        "    docs = loader.load()\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
        "    split_docs = text_splitter.split_documents(docs)\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=my_openai_key)\n",
        "    doc_search = Chroma.from_documents(docs, embeddings)\n",
        "    doc_search_similarity = doc_search.similarity_search(query, k = 2) # Similarity Search\n",
        "    docs_page_content = \"\".join(doc.page_content for doc in doc_search_similarity)\n",
        "    prompt = PromptTemplate(\n",
        "      input_variables = (\"questions\", \"docs\"),\n",
        "      template =\n",
        "      \"\"\"\n",
        "      You are an helpful Consultant that answer questions about Youtube Videos STRICTLY based on the video's transcript.\n",
        "      Let us think step by step. Your major task is to read through the lines, understand content/context and answer the questions posed to you.\n",
        "      Your first and most important task is to REFINE THE QUESTION ASKED BY THE USER, REPHRASING IT TO \"According to the Video transcript, what did the speaker say about the question\" You can then proceed to the next actions.\n",
        "      If the answer is not found, contextually, from the video transcript, please let the user understand that the topic is not discussed in the video.\n",
        "      Think step by step and logically before you provide answers. You will be severely penalized if you provide wrong answers to the questions posed by the user or if you provide answers when the content/context is not found in the video transcript.\n",
        "      Answer the following question: {question} by searching through the following video transcript: {docs}\n",
        "      Only use the factual information, ONLY from the transcript, to answer the question above. Before you answer, make sure that the major keyword(s) in the question are also present in the video transcript - verbatim (word-for-word). DO NOT MAKE ANYTHING UP\n",
        "      If you don't have sufficient information from the transcript to answer the question, please say\n",
        "      \"I don't have sufficient information from the video to answer this question, can you re-word the question or provide more context?\"\n",
        "      If you are asked about an an entity or item that is not mentioned in the video transcript, please say \"This is not mentioned in the video and I can not talk about that\" Check for every entity and item in the question from the video transcript to be very sure before you answer.\n",
        "      Never make any inference if you cannot substantiate the fact from the given transcript. Ensure ALL statements are verified from the transcript before providing them as answers, else, make it known that you are unable to answer.\n",
        "      If you cannot find a given key-phrase or keyword that is included as part of a question, you must NEVER make anything up or provide answers based on guesses. YOUR ANSWERS MUST BE TRACEABLE to the content of the video transcript.\n",
        "      Make sure your statements are not broken in the middle. They must be complete sentences. You must answer all the questions\n",
        "\n",
        "      Answer: Based on this video transcript:\\n\n",
        "      \"\"\"\n",
        "    )\n",
        "\n",
        "    if st.button(\"Execute\"):\n",
        "      chain = LLMChain(llm = llm, prompt = prompt)\n",
        "      response = chain.run(question = query, docs = docs_page_content)\n",
        "      st.write(query)\n",
        "      st.write(\"Answer: \")\n",
        "      st.write(response)"
      ],
      "metadata": {
        "id": "8da9Foofg6mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run ytqueryapp.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "8z08ME4WiHul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EOSWyan2iHoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SUMMARIZE ANY DOCUMENT (PDF, WORD, FILE, WEBSITE YOUTUBE) QUICKLY"
      ],
      "metadata": {
        "id": "Uf41g9HSf_uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain openai\n",
        "!pip install --upgrade --quiet  youtube_search chromadb tiktoken youtube-transcript-api\n",
        "!pip install --upgrade --quiet  langchain-google-genai pillow"
      ],
      "metadata": {
        "id": "bsTMewjRf-OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "\n",
        "# Load Transcript\n",
        "loader = YoutubeLoader.from_youtube_url(\"https://youtu.be/sPzc6hMg7So\", language=[\"en\", \"en-US\"])\n",
        "transcript = loader.load()\n",
        "\n",
        "# Split Transcript\n",
        "splitter = TokenTextSplitter(model_name=\"gpt-3.5-turbo-16k\", chunk_size=2500, chunk_overlap=100)\n",
        "chunks = splitter.split_documents(transcript)\n",
        "\n",
        "# Set up LLM\n",
        "#openai_api_key = \"YOUR_OPENAI_API_KEY\"\n",
        "#llm = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-3.5-turbo-16k\", temperature=0.3)\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "gllm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key = \"AIzaSyBtmPCYd1Zwf7uJIv4mB2ISngAJGqcQ58c\")\n",
        "\n",
        "# Summarize\n",
        "summarize_chain = load_summarize_chain(llm=gllm, chain_type=\"refine\", verbose=True)\n",
        "summary = summarize_chain.run(chunks)\n",
        "\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "8c_YJyj3ekd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHgKQF2MgLLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KBH58FDTgK8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAT WITH ANY WEBSITE/WEBPAGE INTERRACTIVELY\n",
        "###(Provides Answers Based on the Website and the Base Knowledge of the LLM)\n",
        "### (Being Adapted for Youtube, PDF, Word Doc, Text You Type in, Other Document Forms-WIP)"
      ],
      "metadata": {
        "id": "nJGlXF-wiZIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.1.4\n",
        "!pip install langchain_community==0.0.16\n",
        "!pip install langchain_core==0.1.17\n",
        "!pip install langchain_openai==0.0.5\n",
        "!pip install python-dotenv==1.0.1\n",
        "!pip install streamlit==1.30.0\n",
        "!pip install chromadb==0.4.22\n",
        "!pip install beautifulsoup4=4.12.2=py310hca03da5_0"
      ],
      "metadata": {
        "id": "-EpgUYMai7b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install streamlit langchain lanchain-openai beautifulsoup4 python-dotenv chromadb\n",
        "%%writefile myapp.py\n",
        "import streamlit as st\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "import os\n",
        "# my_openai_key = \"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\"\n",
        "# os.environ['OPEN_AI_KEY'] = \"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\" # imported from my previous so that I can use the OpenAI API key\n",
        "#os.environ['OPEN_AI_KEY'] = my_openai_key # imported from my previous\n",
        "# llm = ChatOpenAI(openai_api_key = my_openai_key, temperature = 0) # imported from my previous\n",
        "llm = ChatOpenAI(openai_api_key = \"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\") # imported from my previous\n",
        "# load_dotenv()\n",
        "\n",
        "def get_vectorstore_from_url(url):\n",
        "    # get the text in document form\n",
        "    loader = WebBaseLoader(url)\n",
        "    document = loader.load()\n",
        "\n",
        "    # split the document into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter()\n",
        "    document_chunks = text_splitter.split_documents(document)\n",
        "\n",
        "    # create a vectorstore from the chunks\n",
        "    vector_store = Chroma.from_documents(document_chunks, OpenAIEmbeddings(openai_api_key = \"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\"))\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "def get_context_retriever_chain(vector_store):\n",
        "    llm = ChatOpenAI(openai_api_key = \"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\")\n",
        "\n",
        "    retriever = vector_store.as_retriever()\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "      MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "      (\"user\", \"{input}\"),\n",
        "      (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
        "    ])\n",
        "\n",
        "    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
        "\n",
        "    return retriever_chain\n",
        "\n",
        "def get_conversational_rag_chain(retriever_chain):\n",
        "\n",
        "    llm = ChatOpenAI(openai_api_key = \"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\")\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
        "      MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "      (\"user\", \"{input}\"),\n",
        "    ])\n",
        "\n",
        "    stuff_documents_chain = create_stuff_documents_chain(llm,prompt)\n",
        "\n",
        "    return create_retrieval_chain(retriever_chain, stuff_documents_chain)\n",
        "\n",
        "def get_response(user_input):\n",
        "    retriever_chain = get_context_retriever_chain(st.session_state.vector_store)\n",
        "    conversation_rag_chain = get_conversational_rag_chain(retriever_chain)\n",
        "\n",
        "    response = conversation_rag_chain.invoke({\n",
        "        \"chat_history\": st.session_state.chat_history,\n",
        "        \"input\": user_query\n",
        "    })\n",
        "\n",
        "    return response['answer']\n",
        "\n",
        "# app config\n",
        "st.set_page_config(page_title=\"Chat with websites\", page_icon=\"ðŸ¤–\")\n",
        "st.title(\"Chat with websites\")\n",
        "\n",
        "# sidebar\n",
        "with st.sidebar:\n",
        "    st.header(\"Settings\")\n",
        "    website_url = st.text_input(\"Website URL\")\n",
        "\n",
        "if website_url is None or website_url == \"\":\n",
        "    st.info(\"Please enter a website URL\")\n",
        "\n",
        "else:\n",
        "    # session state\n",
        "    if \"chat_history\" not in st.session_state:\n",
        "        st.session_state.chat_history = [\n",
        "            AIMessage(content=\"Hello, I am a bot. How can I help you?\"),\n",
        "        ]\n",
        "    if \"vector_store\" not in st.session_state:\n",
        "        st.session_state.vector_store = get_vectorstore_from_url(website_url)\n",
        "\n",
        "    # user input\n",
        "    user_query = st.chat_input(\"Type your message here...\")\n",
        "    if user_query is not None and user_query != \"\":\n",
        "        response = get_response(user_query)\n",
        "        st.session_state.chat_history.append(HumanMessage(content=user_query))\n",
        "        st.session_state.chat_history.append(AIMessage(content=response))\n",
        "\n",
        "\n",
        "\n",
        "    # conversation\n",
        "    for message in st.session_state.chat_history:\n",
        "        if isinstance(message, AIMessage):\n",
        "            with st.chat_message(\"AI\"):\n",
        "                st.write(message.content)\n",
        "        elif isinstance(message, HumanMessage):\n",
        "            with st.chat_message(\"Human\"):\n",
        "                st.write(message.content)"
      ],
      "metadata": {
        "id": "pdha4o42i_Fw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9c341d-d20d-403b-ff9c-9f2edd821b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing myapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run myapp.py & npx localtunnel --port 8501 # to run streamlit on colab"
      ],
      "metadata": {
        "id": "mR6YjWvWjNVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c51b8df-1732-4cfd-8214-aca04672edc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPLEMENTING THE SOLUTIONS USING TABS"
      ],
      "metadata": {
        "id": "5xkt3JZ5fNdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile app2.py\n",
        "import streamlit as st\n",
        "st.markdown(\"<h1 style='text-align:center; color: blue;'>Implementing Tabs in Streamlit</h1>\", unsafe_allow_html=True)\n",
        "import streamlit as st\n",
        "tab1, tab2, tab3 = st.tabs([\"Evaluate and Rank Youtube Videos\", \"Ask Your Documents\", \"Generate Questions\"])\n",
        "\n",
        "with tab1:\n",
        "  st.title(\"Welcome to the App that Helps Evaluate Your Youtube Videos\")\n",
        "  user_video = st.text_input(\"Please enter your Youtube link here\")\n",
        "  st.write(f\"We will help you evaluate your link {user_video}\")\n",
        "\n",
        "with tab2:\n",
        "  st.title(\"Ask Your Documents\")\n",
        "  doc_format = st.radio(\"Please select if you want to ask a PDF, a Word Document or a text?\", [\"pdf/msword\", \"youtube\", \"text\"])\n",
        "  if doc_format == \"pdf/msword\":\n",
        "    st.write(\"You have chosen to ask from a pdf/msword file\")\n",
        "  elif doc_format == \"youtube\":\n",
        "    st.write(\"You have chosen to ask from a Youtube video\")\n",
        "  elif doc_format == \"text\":\n",
        "    st.write(\"You have chosen to query a from plain text\")\n",
        "\n",
        "with tab3:\n",
        "  st.title(\"Generate Questions from Your Documents\")\n",
        "  ques_format = st.radio(\"Please select if you want to generate questions from a PDF, a Word Document or a text?\", [\"pdf/msword\", \"youtube\", \"text\"])\n",
        "  if ques_format == \"pdf/msword\":\n",
        "    st.write(\"You have chosen to ask from a pdf/word file\")\n",
        "  elif ques_format == \"youtube\":\n",
        "    st.write(\"You have chosen to ask from a Youtube video\")\n",
        "  elif ques_format == \"text\":\n",
        "    st.write(\"You have chosen to query a from plain text\")"
      ],
      "metadata": {
        "id": "eJTSBefkekT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__PvypQubIzh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STUDY SMARTER ON YOUTUBE"
      ],
      "metadata": {
        "id": "X7vj61ZqdY2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NEW REQUIREMENTS AS AT TODAY 01-03-2024\n",
        "!pip install -U langchain-community streamlit openai\n",
        "!pip install langchain\n",
        "!pip install --upgrade --quiet  youtube_search chromadb tiktoken youtube-transcript-api\n",
        "!pip install --upgrade --quiet  langchain-google-genai pillow"
      ],
      "metadata": {
        "id": "ronNq6PSbSJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Code Itself"
      ],
      "metadata": {
        "id": "KcLnfoMhdv98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile ytqueryapp.py\n",
        "from youtube_search import YoutubeSearch  # Importing YoutubeSearch function\n",
        "from langchain_community.tools import YouTubeSearchTool\n",
        "import os\n",
        "import streamlit as st\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import pandas as pd\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_community.llms import OpenAI\n",
        "#from langchain import OpenAI # langchain_community.llms.OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "#from langchain.vectorstores import Chroma # from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.vectorstores import Chroma\n",
        "#from langchain import PromptTemplate # langchain.prompts.PromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "#from langchain import LLMChain  # Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.\n",
        "import ssl\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "os.environ['OPEN_AI_KEY'] = \"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\"\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "#from langchain.embeddings import OpenAIEmbeddings # import from langchain-community\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "import _thread  # Import the _thread module\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "my_openai_key = \"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\"\n",
        "os.environ['OPEN_AI_KEY'] = my_openai_key\n",
        "st.set_page_config(page_title=\"Youtube Search Assistance\", page_icon=\"ðŸ¤–\")\n",
        "st.title(\"Effective Learning Via Youtube\")\n",
        "#ollm = ChatOpenAI(openai_api_key = my_openai_key, temperature = 0) #Commenting it out so that the model is not loaded everytime\n",
        "# I can introduce Google Gemini Pro here if I dont want to incur cost and have more context length so that I can use k=4\n",
        "# I introduce the code below:\n",
        "# Thankfully, Gemini is compatible with langchain and can be used without any significant change\n",
        "import getpass\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "gllm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key = \"AIzaSyBtmPCYd1Zwf7uJIv4mB2ISngAJGqcQ58c\")\n",
        "# result = llm.invoke(\"Tell me about Nigeria, in nothing less than 3000 words. Write it in ryhmes\")\n",
        "# print(result.content)\n",
        "\n",
        "# STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1 STEP 1\n",
        "#MODULE 1 STARTS HERE - RAN WELL\n",
        "#%%writefile ytqueryapp.py\n",
        "from youtube_search import YoutubeSearch  # Importing YoutubeSearch function  from langchain_community.tools import YouTubeSearchTool\n",
        "import streamlit as st\n",
        "import ast\n",
        "import pandas as pd\n",
        "\n",
        "@st.cache_data # INTRODUCED TODAY 03-01-2024 PERHAPS TO PREVENT THE ERROR BEING THROWN UP BY THE MODEL\n",
        "def process_video_link_request(topic, no_of_links):\n",
        "  integerno = int(no_of_links)  # Converting the user input into Interger Number\n",
        "  results = YoutubeSearch(topic, max_results=integerno).to_dict()  # Generating the link and converting the output to dictionary in a list\n",
        "  df = pd.DataFrame({}) # Now intiating an empty DataFrame with an empty dictionary\n",
        "  for i, result in enumerate(results, start=1):\n",
        "    df = df.append(pd.DataFrame(result))\n",
        "  df = df.reset_index(drop=True) # Reseting the index\n",
        "  df_no_duplicates = df.drop_duplicates(subset='id').reset_index(drop=True) # Dropping Duplicates because there are 2 thumbnails for each video link\n",
        "  start_index = 1  # Ensuring the index starts from 1\n",
        "  df_no_duplicates.index = range(start_index, start_index + len(df_no_duplicates))\n",
        "  new_df = df_no_duplicates.copy()\n",
        "  # Cleaning The Column Names\n",
        "  new_df.columns = [\"Video ID\", \"Thumbnail\", \"Title\", \"Description\", \"Channel Name\", \"Duration(hr:min)\", \"Views\", \"Published\", \"Video Link\"]\n",
        "  new_df[\"Video Link\"] =  \"https://www.youtube.com\" + new_df[\"Video Link\"]       # Making the url a full link to enable a direct click on the link\n",
        "  st.dataframe(new_df)\n",
        "  st.write(\"Function Deployed From the Function Call\") # To Check if Function Executes\n",
        "  return new_df\n",
        "\n",
        "\n",
        "just_titles_with_links = {}  # When it is complaining of not defined\n",
        "user_topic = \"\"  # When it is complaining of not defined\n",
        "actual_new_df = 0  # When it is complaining of not defined\n",
        "no_of_ytlinks = 0  # When it is complaining of not defined\n",
        "\n",
        "if just_titles_with_links not in st.session_state:\n",
        "  st.session_state.just_titles_with_links = {} # Simply to initialize this to an empty something\n",
        "\n",
        "if \"just_video_links\" not in st.session_state:\n",
        "  st.session_state.just_video_links = {} # Simply to initialize this to an empty something\n",
        "\n",
        "\n",
        "from langchain.tools import YouTubeSearchTool\n",
        "st.title(\"The Youtube Search App\")\n",
        "if user_topic not in st.session_state:\n",
        "  st.session_state.user_topic = \"\"\n",
        "st.session_state.user_topic = st.text_input(\"Enter Your Topic of Interest Here\")\n",
        "if no_of_ytlinks not in st.session_state:\n",
        "  st.session_state.no_of_ytlinks = 0\n",
        "st.session_state.no_of_ytlinks = st.number_input(\"Enter the Number of Links Requested Here\", value = 0)  # Add a selection box for choosing the number of links\n",
        "if st.session_state.user_topic is not None and st.session_state.user_topic != \"\" and st.session_state.no_of_ytlinks is not None and st.session_state.no_of_ytlinks != 0:\n",
        "  st.write(f\"You have selected to retrieve {st.session_state.no_of_ytlinks} links on the topic '{st.session_state.user_topic}'.\")     # Display the selected number of links on the topic\n",
        "  if actual_new_df not in st.session_state:\n",
        "    st.session_state.actual_new_df = 0\n",
        "  st.session_state.actual_new_df = process_video_link_request(st.session_state.user_topic, st.session_state.no_of_ytlinks)\n",
        "  st.write(\"Now I have moved on from the Function call\")\n",
        "  st.write(f\"The entire actual dataframe is given as below\")\n",
        "  st.dataframe(st.session_state.actual_new_df)\n",
        "  st.write(\"Now Printing Just the Titles and Links\")  #New Add\n",
        "  st.session_state.just_titles_with_links = st.session_state.actual_new_df[[\"Title\", \"Video Link\"]] #New Add to sub-sect the 2 columns\n",
        "  if st.button(\"Display Only Titles and Links\"):\n",
        "    st.dataframe(st.session_state.just_titles_with_links) # New Add today 19/02/2024\n",
        "  st.session_state.just_video_links = st.session_state.actual_new_df[\"Video Link\"]\n",
        "  if st.button(\"Display Only the Video Links\"):\n",
        "    st.dataframe(st.session_state.just_video_links) # New Add today 20/02/2024 to display only the video links\n",
        "  #if st.session_state.actual_new_df is not None and st.session_state.actual_new_df != \"\":  # Find out the code to check if a DataFrame is not empty or exist.\n",
        "  #if 'st.session_state.actual_new_df' in locals() or 'st.session_state.actual_new_df' in globals():\n",
        "  #if not st.session_state.actual_new_df.any().any():\n",
        "\n",
        "  #MODULE 1 ENDS HERE - RAN WELL\n",
        "#STEP 2 #STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2#STEP 2\n",
        "\n",
        "\n",
        "# MODULE 2 STARTS HERE - RAN WELL\n",
        "#%%writefile ytqueryapp.py\n",
        "#----------------------------\n",
        "#from youtube_search import YoutubeSearch  # Importing YoutubeSearch function\n",
        "#from langchain.chat_models import ChatOpenAI\n",
        "#import os\n",
        "#import streamlit as st\n",
        "#from langchain_community.document_loaders import YoutubeLoader\n",
        "#from langchain import OpenAI\n",
        "#from langchain.text_splitter import CharacterTextSplitter\n",
        "#from langchain.embeddings import OpenAIEmbeddings\n",
        "#from langchain.chains import RetrievalQA\n",
        "#from langchain.vectorstores import Chroma\n",
        "#from langchain import PromptTemplate\n",
        "#from langchain import LLMChain\n",
        "#import _thread  # Import the _thread module\n",
        "#import ssl\n",
        "#from langchain.prompts.chat import ChatPromptTemplate\n",
        "#from langchain import PromptTemplate\n",
        "#from langchain.chains import LLMChain, SequentialChain\n",
        "#my_openai_key = \"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\"\n",
        "#os.environ['OPEN_AI_KEY'] = \"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\"\n",
        "#os.environ['OPEN_AI_KEY'] = my_openai_key\n",
        "#--------------------------------------------\n",
        "\n",
        "#st.set_page_config(page_title=\"Youtube Search Assistance\", page_icon=\"ðŸ¤–\")   # IN THE COMBINED STUFF, I CANNOT CALL PAGE CONFIG TWICE\n",
        "st.title(\"Effective Learning Via Youtube\")\n",
        "#llm = ChatOpenAI(openai_api_key = my_openai_key, temperature = 0) #Commenting it out so that the model is not loaded everytime\n",
        "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "#gllm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key = \"AIzaSyBtmPCYd1Zwf7uJIv4mB2ISngAJGqcQ58c\")\n",
        "\n",
        "\n",
        "@st.cache_data\n",
        "def retrieve_relevant_keywords(user_topic, top_n_keywords):  # Assistance by LLM to help generate relevant Keyword\n",
        "    template_1 = \"Based on the topic {topic}, generate {number} relevant key words/topics/sub-topics that is expected from a video discussion of the topic. What points, sub-topics, key points, e.t.c should the speaker touch on for an effective discussion of the topic? ALWAYS ENSURE THAT YOUR RESPONSES ARE SIMPLE KEYWORDS LISTED AS NUMBERED BULLET POINTS WITHOUT EXPLANATIONS\"\n",
        "    prompt_1 = ChatPromptTemplate.from_template(template_1)\n",
        "    chain_1 = LLMChain(llm=gllm, prompt=prompt_1, output_key='relevant_keywords')\n",
        "    default_relevant_keywords = chain_1.run({'topic': user_topic, 'number': top_n_keywords})\n",
        "    return default_relevant_keywords\n",
        "\n",
        "@st.cache_data\n",
        "def generate_user_keyword_list(user_chosen_keywords): #Function to receive users prefered keyword - manually selected by the user\n",
        "  #user_chosen_keywords = st.text_area(\"Enter your important keywords (each on a new line):\", height=200)\n",
        "  #if st.button(\"Submit Topics\"):\n",
        "    topics_list = [topic.strip() for topic in user_chosen_keywords.split('\\n') if topic.strip()]\n",
        "    return topics_list\n",
        "\n",
        "\n",
        "@st.cache_data\n",
        "def llm_list_to_multiselectbox(llm_keywords):\n",
        "    all_keywords = llm_keywords.split('\\n')\n",
        "    keywords = [keyword.split(':')[-1].split('.')[-1].strip() for keyword in all_keywords if keyword.strip()]\n",
        "    #keywords.insert(0, \"Select Keyword\")\n",
        "    formatted_keyword_output_list = [f\"{keyword}\" for keyword in keywords if keyword]\n",
        "    return formatted_keyword_output_list\n",
        "#------------------------------------------------------------------------------------------\n",
        "\n",
        "if \"keywords_by_user_as_list\" not in st.session_state:\n",
        "  st.session_state.keywords_by_user_as_list = []\n",
        "\n",
        "if \"user_chosen_keywords\" not in st.session_state:\n",
        "  st.session_state.user_chosen_keywords = \"\"\n",
        "\n",
        "st.session_state.user_chosen_keywords = st.text_area(\"Enter your important keywords (each on a new line):\", height=200)\n",
        "\n",
        "if st.button(\"Submit Topics\"):\n",
        "  st.session_state.keywords_by_user_as_list = generate_user_keyword_list(st.session_state.user_chosen_keywords)  # Calling the function to receive users prefered keywords -manual\n",
        "\n",
        "if st.session_state.keywords_by_user_as_list != []:\n",
        "\n",
        "  st.markdown(\"**These are the keywords you have selected manually yourself**\")\n",
        "\n",
        "  st.write(st.session_state.keywords_by_user_as_list)\n",
        "\n",
        "#IMPORTANT- DO THIS FOR BOTH LISTS FOR GREAT USER EXPERIENCE\n",
        "  # Consider using list enumeration to list this out to inform the user that the below are what he/she has chosen\n",
        "  #for i, choice in enumerate(st.session_state.keywords_by_user_as_list):\n",
        "    #print(f\"{i}. {choice}\")\n",
        "#---------------------------------------------------------------------------------------------------\n",
        "\n",
        "if \"no_of_keywords\" not in st.session_state:\n",
        "\n",
        "  st.session_state.no_of_keywords = 0  # Initialized to 0 to prevent zero error\n",
        "\n",
        "st.session_state.no_of_keywords = st.number_input(\"How many key words or related sub-topics do you want this Assistant to generate for you?\", step=1, value=0) # Asking how many keywords the user would like the app to generate for him/her\n",
        "\n",
        "#if st.session_state.no_of_keywords is not None:\n",
        "  #st.session_state.no_of_keywords = int(st.session_state.no_of_keywords)  # converting to integer\n",
        "\n",
        "# if \"keywords_by_user\" not in st.session_state:\n",
        "#   st.session_state.keywords_by_user = \"None\"\n",
        "\n",
        "# st.session_state.keywords_by_user = generate_user_keyword_list()  # Calling the function to receive users prefered keywords -manual\n",
        "\n",
        "# if st.session_state.keywords_by_user:\n",
        "\n",
        "#   st.markdown(\"**These are the keywords you have selected manually yourself**\")\n",
        "\n",
        "#   st.write(st.session_state.keywords_by_user)\n",
        "\n",
        "#if \"user_topic\" not in st.session_state:         # Note that this is already up there @ st.session_state.user_topic = text_input(\"Enter Your Topic of Interest\")\n",
        "    #t.session_state.user_topic = \"\"\n",
        "\n",
        "#st.session_state.user_topic = \"How to have a restful nightrest\"    # For an example HERE IS THE EXAMPLE TOPIC\n",
        "\n",
        "\n",
        "if \"llm_topic_keywords\" not in st.session_state:\n",
        "  st.session_state.llm_topic_keywords = \"None\"\n",
        "\n",
        "if st.session_state.no_of_keywords >= 1:\n",
        "  st.session_state.llm_topic_keywords  = retrieve_relevant_keywords(st.session_state.user_topic, st.session_state.no_of_keywords)    # Calling the function to retrieve relevant keywords from the LLM - assistance by LLM\n",
        "\n",
        "  st.write(\"These are the keywords that this model is suggesting for you\")\n",
        "\n",
        "  st.write(st.session_state.llm_topic_keywords)\n",
        "\n",
        "if \"final_llm_keyword_list\" not in st.session_state:\n",
        "  st.session_state.final_llm_keyword_list = [\"Keyword\"]\n",
        "\n",
        "if st.session_state.llm_topic_keywords:\n",
        "  st.session_state.final_llm_keyword_list = llm_list_to_multiselectbox(st.session_state.llm_topic_keywords)  # Get llm generated keyword to a curated list\n",
        "\n",
        "# May be we should add the 2 keywords together\n",
        "\n",
        "if \"combined_keyword_list\" not in st.session_state:\n",
        "  st.session_state.combined_keyword_list = [\"Keyword\"]\n",
        "if st.session_state.final_llm_keyword_list and st.session_state.keywords_by_user_as_list:  # If the two lists exists\n",
        "  st.session_state.combined_keyword_list = st.session_state.final_llm_keyword_list + st.session_state.keywords_by_user_as_list\n",
        "  st.write(\"This is the combined list of keywords\")\n",
        "  st.write(st.session_state.combined_keyword_list)\n",
        "\n",
        "if \"total_keyword_selection\" not in st.session_state:\n",
        "  st.session_state.total_keyword_selection = [\"None\"]\n",
        "\n",
        "if st.session_state.combined_keyword_list:  # If the list exists\n",
        "\n",
        "  st.session_state.total_keyword_selection = st.multiselect(\"Select Keywords From List\", st.session_state.combined_keyword_list) # The combined keywords selection including the keywords selected by user as the default.\n",
        "\n",
        "  st.write(\"This is what you have selected as your preference in your choice video\")\n",
        "\n",
        "  st.write(st.session_state.total_keyword_selection)\n",
        "\n",
        "#MODULE 2 ENDS HERE\n",
        "#STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STEP 3 #STE\n",
        "\n",
        "# MODULE 3 STARTS HERE - RAN WELL\n",
        "#%%writefile ytqueryapp.py\n",
        "@st.cache_data\n",
        "def evaluate_links(list_of_links, evaluation_criteria):\n",
        "  evaluation_criteria = ', '.join(evaluation_criteria)   # Converting to Strings\n",
        "  my_frame = pd.DataFrame({}, index=[0])  #S Setting up an empty dataframe\n",
        "  #for link in st.session_state.actual_new_df[\"Video Link\"]:  # Trying to loop over the number of links returned for the selection made by user  # What it was before\n",
        "  #for link in list_of_links:  # Trying to loop over the number of links returned for the selection made by user\n",
        "  the_list = [link for link in list_of_links]  # Converting the previous dataframe to a list\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(len(the_list)):  # For i in the range of the number of video links in the selection\n",
        "    loader = YoutubeLoader.from_youtube_url(the_list[i], add_video_info=False)\n",
        "    docs = loader.load()\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    split_docs = text_splitter.split_documents(docs)\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=my_openai_key)\n",
        "    doc_search = Chroma.from_documents(docs, embeddings)\n",
        "    doc_search_similarity = doc_search.similarity_search(evaluation_criteria, k = 2) # Similarity Search\n",
        "    docs_page_content = \"\".join(doc.page_content for doc in doc_search_similarity)\n",
        "\n",
        "    response1 = \"\"\n",
        "    pattern = re.compile(r\"^{[\\s\\S]*}$\")\n",
        "    while not pattern.match(response1):\n",
        "    #-----------------------------------------this is where the error handling and recovery starts simply because an llm is quite indeterminate and can give diverse outputs-----------------------------------------\n",
        "      template_2 = \"\"\"\n",
        "      Let us think step by step. Rate this video by searching through (and STRICTLY BASED) on its video transcript (delimited by double asterics below) and determine how well (to what depth) it discusses each of the following topics/points {criteria}.\n",
        "      For each topic/point in the list, provide a rating - a percentage showing the depth of discussion of each topic/point in the video transcript on a scale of 0-100%. Your evaluation must be based on context similarity and must be fair, logical and consistent with the sliding scale provided.\n",
        "      Let the sliding scale be as below (Be careful NOT to simply prescribe random numbers, but be logical and consistent in your evaluations):\n",
        "      0% - Means that the topic/point was not mentioned at all\n",
        "      1-10% - Means that the topic/point was only (just mentioned) mentioned\n",
        "      11-25% - Means that the topic/point was briefly discussed in addition to being mentioned\n",
        "      26% - 40% - Means that the topic/point was discussed at medium length/depth\n",
        "      41-50% - Means that the topic/point was discussed at a depth slightly above average\n",
        "      51-60% - Means that the topic/point was discussed at very good length\n",
        "      61-70% - Means that the topic/point was discussed in great details\n",
        "      71-80% - Means that the topic/point was excellently discussed in great depth\n",
        "      91-100% - Means that the topic/point was excellently discussed in great depth with examples and illustrations.\n",
        "      Your output/response MUST BE A DICTIONARY with key-value pairs. Each evaluation topic/point will be a key and the corresponding rating for the key will be the value in the result set.\n",
        "      Each of the values in the output dictionary MUST be an INTEGER WITHOUT QUOTATION MARK.\n",
        "      RETURN ONLY THE DICTIONARY WITH THE KEY-VALUE pairs as described above.\n",
        "      NO SINGLE topic/point SHALL BE EVALUATED TWICE/REPEATED.\n",
        "      NO VALUE MUST RETURN a NaN, NO empty values are allowed. Empty values are forbidden and there shall be a serious penalty against you if you make such mistake, be warned.\n",
        "      YOU MUST REMOVE ALL Backticks and any LEADING or TRAILING characters IN THE RESPONSE.\n",
        "      YOU MUST REMOVE ALL Backticks and any LEADING or TRAILING characters IN THE RESPONSE.\n",
        "\n",
        "      **{vid_transcript}**\n",
        "\n",
        "      \"\"\"\n",
        "      # NO VALUE MUST RETURN a NaN, NO empty values are allowed. Empty values are forbidden and there shall be a serious penalty against you if you make such mistake, be warned.\n",
        "      # YOU MUST REMOVE ALL Backticks and any LEADING or TRAILING characters IN THE RESPONSE.\n",
        "      # You will be severely penalized for including any additional character outside the DICTIONARY. THE OUTPUT MUST be of the type dict, NOT a string.\n",
        "      prompt_2 = ChatPromptTemplate.from_template(template_2)\n",
        "      chain_2 = LLMChain(llm = gllm, prompt=prompt_2)   #\n",
        "      #if st.button(\"Execute\"):\n",
        "      chain = LLMChain(llm = gllm, prompt = prompt_2)  # COMMENTING THIS OUT TODAY 01-03-2024 BECAUSE I WAS GETTING ERRORS WITH GOOGLE MODEL\n",
        "      #chain = LLMChain(llm = ollm, prompt = prompt_2) # NOW HERE USING OPEN AI'S MODEL TO GENERATE THE DICTIONARIES TO SEE IF THE ERROR IS PREVENTED.\n",
        "      response = chain_2.run(criteria = evaluation_criteria , vid_transcript = docs_page_content) # not sure why criteria  and vid_transcript are not accepting  \"criteria\"  and \"vid_transcript\" respectively\n",
        "      #response1 = response[3:-3]  # Intended to remove backticks - extracting only the contents within the backticks - It works for once ISOLATING TODAY 29-02-2024\n",
        "      response1 = response.strip() # ADDING TODAY FOR A TEST 29022024\n",
        "      #response1 = response1.strip() # ISOLATING TODAY FOR A TEST  29022024\n",
        "      print(f\"Non Matching format: {response1}\")\n",
        "      #print(type(response1))\n",
        "    #-----------------------------------------this is where the error handling and recovery ends------------------------------------------\n",
        "    print(f\"The Response for this iteration {i} is {response1}\")\n",
        "    print(f\"The Response type for this iteration {i} is properly formatted and shown below:\\n\")\n",
        "    print(type(response1))\n",
        "    if response1:\n",
        "      response_dict = json.loads(response1)\n",
        "      print(f\"Answer for this iteration {i}: \")\n",
        "      print(\"\")\n",
        "      print(f\"Now going through the video with link {the_list[i]}\")\n",
        "      print(\"\")\n",
        "      print(response_dict) # Just print what this iteration returns\n",
        "      addframe = pd.DataFrame(response_dict, [i])\n",
        "      my_frame = my_frame.append(addframe, ignore_index=True) # Adding to the table\n",
        "      #my_frame['Video Link'] = the_list[i]  # Adding the link to each row (each video record)\n",
        "      print(f\"Now transitioning to the next link\")\n",
        "      #index = index.append(i)\n",
        "    time.sleep(5)  # Giving the model some time to rest\n",
        "  return my_frame, the_list\n",
        "\n",
        "\n",
        "@st.cache_data\n",
        "def refine_and_rate_links(evaluated_videos_in_tables, list_of_links):\n",
        "  import numpy as np\n",
        "  evaluated_videos_in_tables = evaluated_videos_in_tables.dropna(thresh = len(evaluated_videos_in_tables.columns)-2) # Dropping Rows with NaN Values thresh\n",
        "  # thresh=3: The thresh parameter specifies the threshold for non-null values. For example, if in this case, it's set to 3, it means that a row will be kept only if it has at least 3 non-null values.\n",
        "  # Set the DataFrame index to your custom list\n",
        "  evaluated_videos_in_tables.set_index(pd.Index(list_of_links), inplace=True)\n",
        "  evaluated_videos_in_tables_sum = evaluated_videos_in_tables.copy()\n",
        "  evaluated_videos_in_tables_sum[\"Score\"] = evaluated_videos_in_tables_sum.sum(axis=1)\n",
        "  evaluated_videos_in_tables_sum[\"Score\"] = np.ceil(evaluated_videos_in_tables_sum[\"Score\"]/(len(evaluated_videos_in_tables.columns)-1))  #final_list in the main code\n",
        "  evaluated_videos_in_tables_sum.sort_values(by='Score', inplace=True, ascending=False)\n",
        "  # Assign a label to the index column\n",
        "  evaluated_videos_in_tables_sum = evaluated_videos_in_tables_sum.rename_axis('Video Link')\n",
        "  evaluated_videos_in_tables_sum = evaluated_videos_in_tables_sum.reset_index() # didnt drop=True\n",
        "  # The reset_index(drop=True) method is used to reset the row indices, and drop=True is used to discard the old index column.\n",
        "  evaluated_videos_in_tables_sum.index = range(1, len(evaluated_videos_in_tables ) + 1)  # DataFrame is reindexed using df.index = range(1, len(df) + 1). This sets the indices to start from 1.\n",
        "  refined_evaluated_table = evaluated_videos_in_tables_sum\n",
        "  return refined_evaluated_table\n",
        "\n",
        "empty = pd.DataFrame({}, index=[0])\n",
        "if \"evaluated_videos_in_tables\" not in st.session_state:\n",
        "  st.session_state.evaluated_videos_in_tables = empty\n",
        "if \"list_of_links\" not in st.session_state:\n",
        "  st.session_state.list_of_links = []\n",
        "\n",
        "#if st.session_state.evaluated_videos_in_tables != empty:  # WATCH OUT FOR THIS I THINK IT SHOULD NOT BE HERE\n",
        "if st.button(\"Evaluate Videos\"):\n",
        "  st.session_state.evaluated_videos_in_tables, st.session_state.list_of_links = evaluate_links(st.session_state.just_video_links, st.session_state.total_keyword_selection)\n",
        "  st.write(\"The evaluated videos is as below\")\n",
        "  st.dataframe(st.session_state.evaluated_videos_in_tables)\n",
        "  st.write(st.session_state.evaluated_videos_in_tables)\n",
        "  st.table(st.session_state.evaluated_videos_in_tables)\n",
        "#   if evaluated_videos_in_tables and list_of_links:\n",
        "#     st.write(\"The evaluated videos is as below\")\n",
        "#     st.dataframe(evaluated_videos_in_tables)\n",
        "  st.write(st.session_state.list_of_links)\n",
        "\n",
        "empty_2 = pd.DataFrame({}, index=[0])\n",
        "if \"final_evaluation\" not in st.session_state:\n",
        "  st.session_state.final_evaluation = empty_2\n",
        "\n",
        "if st.button(\"final_evaluation\"):\n",
        "  st.session_state.final_evaluation = refine_and_rate_links(st.session_state.evaluated_videos_in_tables, st.session_state.list_of_links)\n",
        "  st.write(\"The final evaluation of the videos with Scores is as below\")\n",
        "  st.dataframe(st.session_state.final_evaluation)\n",
        "\n",
        "\n",
        "empty_3 = pd.DataFrame({}, index=[0])\n",
        "if \"just_links_with_scores\" not in st.session_state:\n",
        "  st.session_state.just_links_with_scores = empty_3\n",
        "\n",
        "if \"just_links_and_scores_tostring\" not in st.session_state:\n",
        "  st.session_state.just_links_and_scores_tostring = empty_3\n",
        "\n",
        "if st.button(\"Only Links With Scores\"):\n",
        "  st.session_state.just_links_with_scores = st.session_state.final_evaluation[[\"Video Link\", \"Score\"]]\n",
        "  st.write(\"The Score of Each Link Based on the Chosen Criteria, Links with Scores Only\")\n",
        "  st.dataframe(st.session_state.just_links_with_scores)\n",
        "  st.session_state.just_links_and_scores_tostring = st.session_state.just_links_with_scores.to_string()\n",
        "  st.write(\"st.session_state.just_links_and_scores_tostring\")\n",
        "\n",
        "\n",
        "\n",
        "# if st.button(\"Only Links With Scores\"):\n",
        "#   just_links_with_scores = final_evaluation[[\"Video Link\", \"Score\"]]\n",
        "#   just_links_and_scores_tostring = just_links_with_scores.to_string()\n",
        "#   st.write(\"The Score of Each Link Based on the Chosen Criteria, Links with Scores Only\")\n",
        "#   st.dataframe(just_links_with_scores)\n",
        "#   st.write(\"The Clickable Links below\")\n",
        "#   st.write(\"just_links_and_scores_tostring\")\n"
      ],
      "metadata": {
        "id": "l43NLkrxdofn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209643df-da9e-4dc1-f0cd-26d3377aa43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ytqueryapp.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run ytqueryapp.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "67T1JgdHdocB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fa1483-cc10-4762-aefc-c96f365fbe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wyuL4sCKdoYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBtiZ4LMdoVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MaBhvp_PbSDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ASK GEMINI AND DOWNLOAD IT"
      ],
      "metadata": {
        "id": "89RrGfjIbUCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15:30 23-02-2024"
      ],
      "metadata": {
        "id": "GHoTPwL6cY1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf python-docx streamlit --upgrade --quiet  langchain-google-genai pillow"
      ],
      "metadata": {
        "id": "2u5FsSZ-cQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile askgeminianddownload.py\n",
        "from fpdf import FPDF\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key = \"AIzaSyBtmPCYd1Zwf7uJIv4mB2ISngAJGqcQ58c\")\n",
        "# When you edit the downloaded file, you can save it as word 97-2003 file format\n",
        "from io import BytesIO\n",
        "import streamlit as st\n",
        "from docx import Document\n",
        "import time\n",
        "\n",
        "# Function to create a Word document with given text\n",
        "def create_word_document(text):\n",
        "    doc = Document()\n",
        "    doc.add_paragraph(text)\n",
        "    # Save the document to a BytesIO buffer\n",
        "    buffer = BytesIO()\n",
        "    doc.save(buffer)\n",
        "    buffer.seek(0)\n",
        "\n",
        "    # Save the document with a custom File-name and Download the Word document\n",
        "    my_file_name = st.text_input(\"Save file as\", key = \"safe-file-word\")\n",
        "    my_file_name = \"\".join([my_file_name, \".docx\"])\n",
        "    if st.download_button(\n",
        "            label=\"Download Word Document\",\n",
        "            data=buffer,\n",
        "            file_name = my_file_name,\n",
        "            key=\"word_download\",\n",
        "        ):\n",
        "      # Create a feel of progress for good user experience\n",
        "      progress_bar = st.progress(0)\n",
        "      for percent_complete in range(100):\n",
        "        progress_bar.progress(percent_complete + 1)\n",
        "        time.sleep(0.005)\n",
        "      st.success(f\"{my_file_name} downloaded successfully\")\n",
        "\n",
        "\n",
        "def create_and_download_pdf_file(text):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, text)\n",
        "\n",
        "    #Now save it\n",
        "    # Save the document to a BytesIO buffer\n",
        "    buffer = BytesIO()\n",
        "    pdf_content = pdf.output(dest=\"S\").encode(\"latin1\")\n",
        "    #pdf_content = pdf.output(dest=\"S\").encode(\"utf-8\")\n",
        "    buffer.write(pdf_content)\n",
        "    buffer.seek(0)\n",
        "\n",
        "    # Save the document with a custom File-name and Download the Word document\n",
        "    my_file_name = st.text_input(\"Save file as\", key = \"safe-file-pdf\")\n",
        "    my_file_name = \"\".join([my_file_name, \".pdf\"])\n",
        "    if st.download_button(\n",
        "            label=\"Download PDF Document\",\n",
        "            data=buffer,\n",
        "            file_name = my_file_name,\n",
        "            key=\"pdf_download\",\n",
        "        ):\n",
        "      # Create a feel of progress for good user experience\n",
        "      progress_bar = st.progress(0)\n",
        "      for percent_complete in range(100):\n",
        "        progress_bar.progress(percent_complete + 1)\n",
        "        time.sleep(0.005)\n",
        "      st.success(f\"{my_file_name} downloaded successfully\")\n",
        "\n",
        "\n",
        "st.title(\"GeminiGPT - Fountain of Knowledge\")\n",
        "st.markdown(\"**You Can Type Your Questions Here, We Will Give You The Answers**\")\n",
        "st.write(\"\")\n",
        "your_prompt = st.text_input(\"Your Input Here- What exactly do you want to achieve? Be detailed and specific\", key = \"text-input-key\")\n",
        "result = llm.invoke(your_prompt)\n",
        "#st.write(\"Text to download:\", your_prompt)\n",
        "main_content = result.content\n",
        "if your_prompt and your_prompt != \"\" and your_prompt is not None:\n",
        "  st.write(\"The result of your request is as below. You can download it as word document or pdf if you wish\")\n",
        "  st.write(main_content)\n",
        "  create_word_document(main_content)\n",
        "  st.write(\"or\")\n",
        "  create_and_download_pdf_file(main_content)"
      ],
      "metadata": {
        "id": "My7y1vJBcQFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWkv1gwYcQCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1Fn4SwdcP_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpM5-bXNcP8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile askgeminianddownload.py\n",
        "from fpdf import FPDF\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key = \"AIzaSyBtmPCYd1Zwf7uJIv4mB2ISngAJGqcQ58c\")\n",
        "# When you edit the downloaded file, you can save it as word 97-2003 file format\n",
        "from io import BytesIO\n",
        "import streamlit as st\n",
        "from docx import Document\n",
        "import time\n",
        "\n",
        "# Function to create a Word document with given text\n",
        "def create_word_document(text):\n",
        "    doc = Document()\n",
        "    doc.add_paragraph(text)\n",
        "    # Save the document to a BytesIO buffer\n",
        "    buffer = BytesIO()\n",
        "    doc.save(buffer)\n",
        "    buffer.seek(0)\n",
        "\n",
        "    # Save the document with a custom File-name and Download the Word document\n",
        "    my_file_name = st.text_input(\"Save file as\", key = \"safe-file-word\")\n",
        "    my_file_name = \"\".join([my_file_name, \".docx\"])\n",
        "    if st.download_button(\n",
        "            label=\"Download Word Document\",\n",
        "            data=buffer,\n",
        "            file_name = my_file_name,\n",
        "            key=\"word_download\",\n",
        "        ):\n",
        "      # Create a feel of progress for good user experience\n",
        "      progress_bar = st.progress(0)\n",
        "      for percent_complete in range(100):\n",
        "        progress_bar.progress(percent_complete + 1)\n",
        "        time.sleep(0.005)\n",
        "      st.success(f\"{my_file_name} downloaded successfully\")\n",
        "\n",
        "\n",
        "def create_and_download_pdf_file(text):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, text)\n",
        "\n",
        "    #Now save it\n",
        "    # Save the document to a BytesIO buffer\n",
        "    buffer = BytesIO()\n",
        "    pdf_content = pdf.output(dest=\"S\").encode(\"latin1\")\n",
        "    #pdf_content = pdf.output(dest=\"S\").encode(\"utf-8\")\n",
        "    buffer.write(pdf_content)\n",
        "    buffer.seek(0)\n",
        "\n",
        "    # Save the document with a custom File-name and Download the Word document\n",
        "    my_file_name = st.text_input(\"Save file as\", key = \"safe-file-pdf\")\n",
        "    my_file_name = \"\".join([my_file_name, \".pdf\"])\n",
        "    if st.download_button(\n",
        "            label=\"Download PDF Document\",\n",
        "            data=buffer,\n",
        "            file_name = my_file_name,\n",
        "            key=\"pdf_download\",\n",
        "        ):\n",
        "      # Create a feel of progress for good user experience\n",
        "      progress_bar = st.progress(0)\n",
        "      for percent_complete in range(100):\n",
        "        progress_bar.progress(percent_complete + 1)\n",
        "        time.sleep(0.005)\n",
        "      st.success(f\"{my_file_name} downloaded successfully\")\n",
        "\n",
        "st.title(\"GeminiGPT - Fountain of Knowledge\")\n",
        "st.markdown(\"**You Can Type Your Questions Here, We Will Give You The Answers**\")\n",
        "st.write(\"\")\n",
        "your_prompt = st.text_input(\"Your Input Here- What exactly do you want to achieve? Be detailed and specific\", key = \"text-input-key\")\n",
        "result = llm.invoke(your_prompt)\n",
        "#st.write(\"Text to download:\", your_prompt)\n",
        "main_content = result.content\n",
        "if your_prompt and your_prompt != \"\" and your_prompt is not None:\n",
        "  st.write(\"The result of your request is as below. You can download it as word document or pdf if you wish\")\n",
        "  st.write(main_content)\n",
        "  create_word_document(main_content)\n",
        "  st.write(\"or\")\n",
        "  create_and_download_pdf_file(main_content)"
      ],
      "metadata": {
        "id": "crSqGJ4_bZJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pq46UN5sbpxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile askgeminianddownload.py\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key = \"AIzaSyBtmPCYd1Zwf7uJIv4mB2ISngAJGqcQ58c\")\n",
        "# When you edit the downloaded file, you can save it as word 97-2003 file format\n",
        "from io import BytesIO\n",
        "import streamlit as st\n",
        "from docx import Document\n",
        "import time\n",
        "\n",
        "# Function to create a Word document with given text\n",
        "def create_word_document(text):\n",
        "    doc = Document()\n",
        "    doc.add_paragraph(text)\n",
        "    # Save the document to a BytesIO buffer\n",
        "    buffer = BytesIO()\n",
        "    doc.save(buffer)\n",
        "    buffer.seek(0)\n",
        "\n",
        "    # Save the document with a custom File-name and Download the Word document\n",
        "    my_file_name = st.text_input(\"Save file as\")\n",
        "    my_file_name = \"\".join([my_file_name, \".docx\"])\n",
        "    if st.download_button(\n",
        "            label=\"Download Word Document\",\n",
        "            data=buffer,\n",
        "            file_name = my_file_name,\n",
        "            key=\"word_download\",\n",
        "        ):\n",
        "      # Create a feel of progress for good user experience\n",
        "      progress_bar = st.progress(0)\n",
        "      for percent_complete in range(100):\n",
        "        progress_bar.progress(percent_complete + 1)\n",
        "        time.sleep(0.005)\n",
        "      st.success(f\"{my_file_name} downloaded successfully\")\n",
        "\n",
        "# Text to be downloaded as Word document\n",
        "#text_to_download = \"Fundamentals of AI\"\n",
        "\n",
        "# Display the text\n",
        "#st.write(\"Text to download:\", text_to_download)\n",
        "\n",
        "# Then download it\n",
        "\n",
        "your_prompt = st.text_input(\"Your Input Here- What exactly do you want to achieve? Be detailed and specific\")\n",
        "result = llm.invoke(your_prompt)\n",
        "st.write(\"Text to download:\", your_prompt)\n",
        "main_content = result.content\n",
        "st.write(\"The result of your request is as below. You can download it as word document if you wish\")\n",
        "st.write(main_content)\n",
        "create_word_document(main_content)\n",
        "\n"
      ],
      "metadata": {
        "id": "5RULvjl1bpmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}